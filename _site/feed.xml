<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-08-06T22:04:34+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Do-Hyeon Lee</title><subtitle>Do-Hyeon&apos;s blog</subtitle><author><name>Do-Hyeon Lee</name></author><entry><title type="html">Bridging the gap between subsymbolic and symbolic systems</title><link href="http://localhost:4000/Bridging-the-gap-between-Subsymbolic-and-Symbolic-Systems/" rel="alternate" type="text/html" title="Bridging the gap between subsymbolic and symbolic systems" /><published>2024-07-24T00:00:00+09:00</published><updated>2024-07-24T00:00:00+09:00</updated><id>http://localhost:4000/Bridging%20the%20gap%20between%20Subsymbolic%20and%20Symbolic%20Systems</id><content type="html" xml:base="http://localhost:4000/Bridging-the-gap-between-Subsymbolic-and-Symbolic-Systems/"><![CDATA[<h1 id="bridging-the-gap-between-sub-symbolic-and-symbolic-systems">Bridging the Gap Between Sub-symbolic and Symbolic Systems</h1>

<p>Modern advancements in artificial intelligence and robotics have made significant progress in mimicking high-level human behaviors and decision-making. Particularly, Deep Reinforcement Learning (DRL) has succeeded in implementing complex behaviors that surpass traditional control problems. While Finite State Machines (FSM) were used in the past for robots performing games or simple tasks, Behavior Trees (BT) have become widely applied recently. This shift, along with technological advancements, presents new approaches to solving complex problems.</p>

<p>Deep Reinforcement Learning indeed offers more possibilities than traditional control methods. This technology is being applied in real-world tasks, helping to solve various challenges we face. However, the complexity and learning processes of deep neural networks function like a black box, potentially causing inductive bias. Therefore, we must exercise caution when using sub-symbolic systems, such as artificial neural networks. Recent incidents related to Tesla’s autonomous driving technology highlight these concerns, leading many countries to strengthen relevant legislation to enhance AI safety and reliability. Modern machines thus need more responsive and modular world models to address such issues effectively.</p>

<p>Moreover, modern machines are neither as fast nor as energy-efficient as the reflexes of humans or animals. While most machines focus on single tasks, humans and animals possess various skills to solve the more challenging and complex task of survival in the world. Constructing reactive and modular world models enables flexible responses to complex environments and easy partial modifications. To implement true autonomous agents, these reactive and modular world models are necessary. These models are closely related to high-level cognitive functions and metacognition in humans.</p>

<p>Humans act based on their understanding of language and the physical world through complex deep neural networks or self-supervised world models. These behaviors are often implicit or explicit and can be considered finite state machines or behavior trees at a macro level. For example, Jurgen Schmidhuber proposed the Gödel Machine, emphasizing that the core ability of consciousness is to modify internal programs and develop better ones. This suggests that humans continually develop and refine useful programs or symbolic systems from sub-symbolic systems like neural networks. Recent consciousness studies also focus on high-level cognitive functions and metacognition, demonstrating how high-level perspectives continuously influence lower-level perspectives in viewing the world (mind), biological reconstruction through learning (brain), and interactions with the physical world (behavior).</p>

<p>Phenomena like hypnosis and subliminal messaging techniques, which operate through language and sensory information, exemplify this self-modifying ability. However, there is little discussion on the techniques or methods for displaying the sub-symbolic contents of deep neural networks in a symbolic form. This is similar to how understanding human behaviors and habits, and expressing the underlying beliefs and subconscious, is possible only through reflection and self-evaluation. As the famous saying goes, “Beliefs become thoughts, thoughts become words, words become actions, actions become habits, habits determine one’s values, and values determine one’s destiny.” To change our destiny and values, we must change our actions and habits, and to do that, we must change our beliefs and words. For instance, several current research approaches strive to address these technical challenges.</p>

<p>In conclusion, it is crucial to explore how sub-symbolic systems autonomously generate and modify high-level symbolic behaviors and clear guidelines. Extracting and evaluating the behavior patterns implicitly stored in already developed sub-symbolic systems is also essential. This process is not only a technically challenging task but also a critical research field determining the future of artificial intelligence. Therefore, advancing modern AI requires an in-depth study of the interactions between sub-symbolic and symbolic systems to develop more flexible and efficient autonomous agents. We must continue our efforts to solve these complex problems.</p>

<hr />

<h3 id="summary">Summary</h3>

<blockquote>
  <p>Modern AI and robotics have made significant strides in mimicking high-level human behaviors and decision-making, particularly through Deep Reinforcement Learning (DRL), which has succeeded in implementing complex behaviors. While traditional control methods like Finite State Machines (FSM) and Behavior Trees (BT) are being replaced by DRL in practical applications, the complexity and inductive bias of deep neural networks necessitate careful use of sub-symbolic systems. Incidents such as Tesla’s autonomous driving accidents highlight these concerns. Modern machines are not as fast or energy-efficient as human or animal reflexes, and typically focus on single tasks, whereas humans and animals use reactive and modular world models for flexible adaptation. Constructing such models is essential for true autonomous agents and closely related to high-level cognitive functions and metacognition. Phenomena like hypnosis and subliminal messaging show self-modifying abilities through language and sensory information, but techniques to display sub-symbolic contents symbolically are lacking. As the saying goes, “Beliefs become thoughts, thoughts become words, words become actions, actions become habits, habits determine one’s values, and values determine one’s destiny,” indicating the need to change beliefs and words to alter actions and habits. Current research approaches aim to address these challenges. In conclusion, exploring how sub-symbolic systems autonomously generate and modify high-level symbolic behaviors is crucial, as is extracting and evaluating implicit behavior patterns. This research is vital for advancing AI and developing flexible and efficient autonomous agents, necessitating continued efforts to solve these complex problems.</p>
</blockquote>]]></content><author><name>Do-Hyeon Lee</name></author><category term="Beliefs" /><category term="Language" /><category term="Symbolic Systems" /><summary type="html"><![CDATA[Bridging the Gap Between Sub-symbolic and Symbolic Systems]]></summary></entry><entry><title type="html">Toward unified science of mind Brain Behavior</title><link href="http://localhost:4000/Toward-Unified-Science-of-Mind-Brain-Behavior/" rel="alternate" type="text/html" title="Toward unified science of mind Brain Behavior" /><published>2024-07-23T00:00:00+09:00</published><updated>2024-07-23T00:00:00+09:00</updated><id>http://localhost:4000/Toward%20Unified%20Science%20of%20Mind-Brain-Behavior</id><content type="html" xml:base="http://localhost:4000/Toward-Unified-Science-of-Mind-Brain-Behavior/"><![CDATA[<h1 id="toward-unified-science-of-mind-brain-behavior">Toward Unified Science of Mind-Brain-Behavior</h1>

<p>The information revolution and the cybernetics movement of the mid-20th century significantly influenced not only physics but also the academic approach to the human mind and spirit, the brain and body, and the behavior of human and animal societies. As the relationship between information and mathematical forms began to gain attention during this period, information theory and statistical mechanics underwent significant changes. These movements aimed to formalize the academic study of human nature and life, but due to technological limitations and philosophical issues at the time, they are <strong>proliferated</strong> into numerous fields in the latter half of the 20th century, including psychology, psychiatry, neurology, neuroscience, economics, anthropology, artificial intelligence, and robotics.</p>

<p>Looking at the history of physics, the development of <strong>principles</strong>, <strong>mechanics</strong>, and <strong>dynamics</strong> that correspond to the questions of ‘why,’ ‘how,’ and ‘what’ is necessary to create robust theories capable of explaining, controlling, and predicting new phenomena. Currently, there exists a confusion of various dynamics, mechanics, and principles that partially explain the mind-brain/body-behavior relationships.</p>

<p>In this context, a <strong>normative theoretical approach</strong> that seeks to integrate and reduce various academic frameworks has significantly developed. Notable examples include Karl Friston’s Free Energy Principle and Active Inference, and Samuel Gershman’s Inductive Bias / Approximation Principle. These theories focus on explaining biological systems and psychological and behavioral phenomena. However, there still exist complex phenomena such as consciousness, feelings, and hypnosis that modern science fails to explain. These phenomena involve biological complexity and evolutionary characteristics, which may not be sufficiently explained by simple physical or information-theoretic approaches. Therefore, an integrated and multidimensional approach across various academic fields is needed to understand them.</p>

<p>While these approaches focus on finding the ‘why,’ modern artificial intelligence research emphasizes the ‘how,’ i.e., <strong>engineering applications</strong>. Concepts like Jurgen Schmidhuber’s Self-supervised Learning and World Model, Geoffrey Hinton’s Boltzmann Machine, and David Rumelhart’s Helmholtz Machine have presented crucial ideas for developing AI that resembles human intelligence. Given that information theory is not a mere subset of physics but holds a unique status, it might necessitate the introduction of irreducible additional principles and the formation of a set of diverse principles.</p>

<p>The language of modern artificial intelligence fundamentally uses various mathematical forms grounded in <strong>information theory</strong>, such as information geometry and Optimal Transport. Just as E. T. Jaynes reinterpreted statistical mechanics from the perspective of information theory, suggesting an integrative relationship between the two fields, exploring the intersection of information theory and physics can yield new insights. This integrative approach shows how information-theoretic principles and physical laws complement each other to explain mind-brain-behavior systems.</p>

<p>In conclusion, understanding the mind-brain-behavior system requires an integrative approach <strong>combining information theory and physical principles</strong>. Information-theoretic principles explain how physical systems process information, predict, and regulate behavior, while physical laws provide a fundamental understanding of how these systems actually operate. Exploring the intersection of information theory and physics can contribute to new research and discoveries. This essay provides critical insights for building an integrated scientific system to understand the mind-brain-behavior system better, thereby laying the foundation for comprehending the functioning of complex biological systems.</p>

<hr />

<h3 id="summary">Summary</h3>

<blockquote>
  <p>The information revolution and the cybernetics movement of the mid-20th century significantly influenced the study of the human mind and behavior, promoting the development of information theory and statistical mechanics, and leading to diversification into various academic fields. The development of principles, mechanics, and dynamics to address the ‘why,’ ‘how,’ and ‘what’ questions in physics is necessary. Normative theoretical approaches integrating multiple disciplines have developed, exemplified by Karl Friston’s Free Energy Principle and Samuel Gershman’s Inductive Bias Principle. However, complex phenomena like consciousness and feelings require a multidimensional approach beyond simple physical theories. Modern AI research focuses on the ‘how,’ with significant contributions from researchers like Jurgen Schmidhuber and Geoffrey Hinton. Information theory provides new insights at the intersection with physics, crucial for understanding mind-brain-behavior systems. Integrating information theory and physical principles helps to comprehend complex biological systems better.</p>
</blockquote>]]></content><author><name>Do-Hyeon Lee</name></author><category term="Beliefs" /><category term="Mind" /><category term="Behavior" /><category term="Brain" /><category term="Philosophy of Science" /><summary type="html"><![CDATA[Toward Unified Science of Mind-Brain-Behavior]]></summary></entry><entry><title type="html">Karl popper’s worlds 1, 2, and 3</title><link href="http://localhost:4000/Karl-Popper's-Worlds-1,-2,-and-3/" rel="alternate" type="text/html" title="Karl popper’s worlds 1, 2, and 3" /><published>2024-07-21T00:00:00+09:00</published><updated>2024-07-21T00:00:00+09:00</updated><id>http://localhost:4000/Karl%20Popper&apos;s%20Worlds%201,%202,%20and%203</id><content type="html" xml:base="http://localhost:4000/Karl-Popper&apos;s-Worlds-1,-2,-and-3/"><![CDATA[<h1 id="karl-poppers-worlds-1-2-and-3">Karl Popper’s Worlds 1, 2, and 3</h1>

<blockquote>
  <p>“… But the problem of the body-mind relationship is a serious problem. It includes the problem of human freedom, which in every respect, including politics, is a fundamental problem; and it includes the problem of man’s position in the physical world, the physical cosmos…”</p>
</blockquote>

<p>Karl Popper reveals his deep interest in the mind-body problem in the second chapter of his book “All Life is Problem Solving.”</p>

<p>Popper considered the mind-body problem to be a crucial philosophical issue closely related to human freedom. He explained the world in terms of <strong>the physical world (World 1)</strong>, <strong>the world of conscious processes (World 2)</strong>, and <strong>the world of objective creations of the human mind (World 3)</strong>. These three worlds interact, and particularly, the existence of World 3 is essential in explaining human self-consciousness through its close connection with World 2.</p>

<p>World 3 is a virtual world consisting of scientific theories, mathematical concepts, works of art, literature, laws, and moral values, all products of the human mind. While these do not directly exist in the physical world, they function as if they are real because we can think and discuss them. Popper believed that through World 3, humans can influence the physical world. Abstract concepts like Newton’s theory of gravity or Einstein’s theory of relativity, though intangible, have led to technological advancements and created tangible changes in the physical world.</p>

<p>Popper’s concept of Worlds 1, 2, and 3 is also useful in exploring the implications of artificial intelligence and information technology on human civilization. AI and information technology serve as tools that extend and deepen World 3. AI analyzes vast amounts of data, discovers new patterns, and generates creative ideas, showing its role beyond being a mere tool and collaborating with humans to enrich World 3’s creations.</p>

<p>Moreover, AI with consciousness or feelings can perform functions similar to human conscious processes (World 2). Such AI learns from interactions with humans, exhibits emotional responses, and solves problems creatively. This suggests that AI can develop a form of self-awareness, prompting a reevaluation of human self-consciousness and freedom in a new dimension.</p>

<p>The development of AI and information technology significantly impacts the physical world (World 1). Innovations such as autonomous vehicles, smart cities, and advanced medical technologies lead the way in transforming the physical world. These changes fundamentally restructure human lifestyles and create new interaction modes between humans and AI.</p>

<p>Popper’s concept of Worlds 1, 2, and 3 shows that AI and information technology have significant implications for human civilization’s advancement. AI shares and expands human uniqueness, creates new innovative products, and traverses physical and conscious processes, playing a vital role in deepening our understanding of existence and civilization.</p>

<hr />

<h3 id="summary">Summary</h3>

<blockquote>
  <p>In his book “All Life is Problem Solving,” Karl Popper considered the mind-body problem as a crucial philosophical issue closely related to human freedom. He explained the world by dividing it into three realms: the physical world (World 1), the world of human conscious processes (World 2), and the objective creations of the human mind (World 3). Popper argued that these three worlds interact to form human self-awareness and civilization. Artificial intelligence and information technology expand and deepen World 3, collaborating with humans to generate new knowledge and creative ideas, thereby bringing about tangible changes in the physical world. These technologies share and extend human uniqueness, playing a significant role in deepening our understanding of existence and civilization.</p>
</blockquote>]]></content><author><name>Do-Hyeon Lee</name></author><category term="Consciousness" /><category term="Philosophy of Mind" /><summary type="html"><![CDATA[Karl Popper’s Worlds 1, 2, and 3]]></summary></entry><entry><title type="html">Schmidhuber and conscious machine</title><link href="http://localhost:4000/Schmidhuber-and-Conscious-Machine/" rel="alternate" type="text/html" title="Schmidhuber and conscious machine" /><published>2024-07-20T00:00:00+09:00</published><updated>2024-07-20T00:00:00+09:00</updated><id>http://localhost:4000/Schmidhuber%20and%20Conscious%20Machine</id><content type="html" xml:base="http://localhost:4000/Schmidhuber-and-Conscious-Machine/"><![CDATA[<h1 id="schmidhuber-and-conscious-machine">Schmidhuber and Conscious Machine</h1>

<iframe width="560" height="315" src="https://www.youtube.com/embed/q4fFuZgOZn8?si=PqlGxV8uUUYBd84x" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>

<p>At the 2016 AI conference in New York, Jürgen Schmidhuber introduced intriguing concepts such as Artificial Consciousness, World Model, Predictive Coding, and Data Compression. He claims that artificial systems with consciousness already exist in his lab, and consciousness arises as a byproduct of data compression during problem-solving. Let’s delve into his main ideas.</p>

<h3 id="1-the-foundation-of-artificial-consciousness-data-compression">1. The Foundation of Artificial Consciousness: Data Compression</h3>

<div style="display: flex;">
  <div style="flex: 8; padding-right: 10px;">
    <p>
      Schmidhuber explains consciousness as a byproduct of data compression. According to his theory, the ability of artificial systems to efficiently compress data during problem-solving forms the basis of consciousness. This is similar to how the human brain processes and stores complex information.
    </p>
  </div>
  <div style="flex: 2;">
    <img src="/assets/images/240720/Untitled.png" alt="Schmidhuber's Thesis" style="width: 100%;" />
  </div>
</div>

<h3 id="2-general-purpose-computer-and-recurrent-neural-networks">2. General-Purpose Computer and Recurrent Neural Networks</h3>

<p>General-purpose computers, especially recurrent neural networks, are optimized for communication costs with many nodes and short wires connecting processors. These computers gather various information from the world to achieve goals or optimize rewards. Recurrent neural networks play a crucial role in this process.</p>

<h3 id="3-world-model-and-predictive-coding">3. World Model and Predictive Coding</h3>

<div style="display: flex;">
  <div style="flex: 2;">
    <img src="/assets/images/240720/Untitled 1.png" alt="World Model + RL" style="width: 100%;" />
  </div>
  <div style="flex: 8; padding-left: 10px;">
    <p>
      Schmidhuber proposes a system that solves reinforcement learning and planning based on two recurrent neural networks: the controller and the world model. The controller generates actions, while the world model compresses data by making predictions about the world. All physical laws and scientific principles are compressed into sub-networks of the recurrent neural network, which are utilized by the controller.
    </p>
  </div>
</div>

<h3 id="4-self-awareness-and-artificial-curiosity">4. Self-awareness and Artificial Curiosity</h3>

<div style="display: flex;">
  <div style="flex: 1;">
    <img src="/assets/images/240720/Untitled 2.png" alt="Robotics Application" style="width: 100%;" />
  </div>
  <div style="flex: 1; padding-left: 10px;">
    <img src="/assets/images/240720/Untitled 3.png" alt="GAN" style="width: 100%;" />
  </div>
</div>
<p>In the process of interacting with the world, artificial systems also compress their own states. This forms the basis for self-awareness. Additionally, Schmidhuber introduced artificial curiosity through Generative Adversarial Networks (GANs), presenting agents that learn via un/self-supervised learning. This is based on a minimax game where the objective function of one neural network is minimized by another.</p>

<h3 id="5-neural-networks-as-programs">5. Neural Networks as Programs</h3>

<div style="display: flex;">
  <div style="flex: 8; padding-right: 10px;">
    <p>
      Schmidhuber argues that the weights of neural networks should be regarded as programs. The main goal of deep neural networks is to learn useful internal representations of observed data. The output of a neural network is differentiable concerning the program, guiding the search for better programs.
    </p>
  </div>
  <div style="flex: 2;">
    <img src="/assets/images/240720/Untitled₩4.png" alt="Neural Economy" style="width: 100%;" />
  </div>
</div>

<h3 id="6-predictive-world-models-and-self-awareness">6. Predictive World Models and Self-awareness</h3>

<div style="display: flex;">
  <div style="flex: 2;">
    <img src="/assets/images/240720/Untitled₩5.png" alt="On Consciousness" style="width: 100%;" />
  </div>
  <div style="flex: 8; padding-left: 10px;">
    <p>
      Predictive world models that interact with the world through the controller learn to efficiently encode actions and observations through predictive coding during their lifetime. In this process, the world model forms a hierarchy of features, identifying anomalies or generating prototype encodings from the given data structure.
    </p>
  </div>
</div>

<h3 id="conclusion">Conclusion</h3>

<p>Jürgen Schmidhuber has been researching machines with artificial consciousness and emotions for 30 years. His research suggests that artificial systems can form self-awareness, interact with the world, and ultimately possess emotions and consciousness through data compression, recurrent neural networks, world models, and predictive coding. This research provides a new perspective on the future of artificial intelligence and contributes to the development of more advanced artificial systems.</p>

<p>Reflection
Considering that the importance of predictive coding and un/self-supervised learning began to be recognized in the 2010s, it is remarkable that he identified the importance of these concepts and applied them to various cases as early as the early 1990s. Notably, Anil Seth’s 2010s theory in the field of consciousness argues that predictive coding of interoceptive information forms the basis of consciousness and self-awareness. This can relate to the compressed state of self in Schmidhuber’s world model. Additionally, the perspective of data compression aligns with Samuel Gershman’s second principle of human cognition, the principle of approximation, recently presented in his book. Data compression is not always possible, but Schmidhuber’s assertion that it forms hierarchies in recursive neural networks is deeply related.</p>

<p>According to his 2003 follow-up research, he introduces a formal definition of consciousness. If consciousness is defined as the ability for unlimited self-inspection and self-modification, the Gödel Machine provides a technical justification for the consciousness of artificial intelligence. By enabling limited self-inspection and self-modification, these machines offer a framework for general problem solvers capable of autonomously improving and optimizing their behavior. This achieves a form of artificial intelligence consciousness based on mathematical proofs and formal reasoning.</p>

<p>His information-theoretic and formal-theoretic stance and research methodology are compelling, with clarity and deep insight. However, considering the biological complexity and functions emphasized in psychology, it is necessary to discover and understand the connections with computational neuroscience and philosophy. For example, a clear explanation is needed on how primordial consciousness, as argued by affective neuroscience, can induce feelings and emotions in agents with Schmidhuber’s world model. Furthermore, in-depth research is required on the relationships between his theory and interoceptive inference, self, attention and consciousness, metacognition, and the Gödel Machine.</p>

<p>While Schmidhuber’s research provides clear and deep insights from an information-theoretic and formal-theoretic perspective, it is necessary to further explore its connections with the biological complexity and functions emphasized in psychology. For example, a clear explanation is needed on how primordial consciousness, as argued by affective neuroscience, can induce feelings and emotions in agents with Schmidhuber’s world model. Furthermore, in-depth research is required on the relationships between his theory and interoceptive inference, self, attention and consciousness, metacognition, and the Gödel Machine.</p>

<h3 id="summary">Summary</h3>

<blockquote>
  <p>At the 2016 AI conference, Jürgen Schmidhuber introduced concepts of artificial consciousness, world model, predictive coding, and data compression, explaining consciousness as a byproduct of data compression during problem-solving. He proposed systems based on general-purpose computers and recurrent neural networks that gather information from the world to achieve goals and optimize rewards, using two recurrent neural networks, the controller, and the world model, for reinforcement learning and planning. These systems efficiently compress data and form self-awareness, considering the weights of neural networks as programs to guide the search for better programs. Notably, Schmidhuber recognized the importance of predictive coding and un/self-supervised learning as early as the early 1990s, connecting with Anil Seth’s interoceptive information predictive coding theory and Samuel Gershman’s data compression principle. His 2003 research introduced a formal definition of consciousness, proposing the Gödel Machine as a technical justification for AI consciousness, offering a framework for general problem solvers capable of autonomously improving their behavior. His research provides new insights into the future of AI and contributes to the development of more advanced artificial systems.</p>
</blockquote>

<h3 id="reference">Reference</h3>

<p><strong>[1] <a href="https://youtu.be/q4fFuZgOZn8?si=yJkWs44y-QBFlKN2">Jürgen Schmidhuber’s Solution to AI Consciousness</a></strong></p>

<p><strong>[2] <a href="https://people.idsia.ch/~juergen/world-models-planning-curiosity-fki-1990.html">1990: Planning &amp; Reinforcement Learning with Recurrent World Models and Artificial Curiosity</a></strong></p>

<p><strong>[3] <a href="https://people.idsia.ch/~juergen/very-deep-learning-1991.html">1991: First very deep learning with unsupervised pre-training</a></strong></p>

<p><strong>[4] <a href="https://mediatum.ub.tum.de/doc/1290203/document.pdf">Godel Machines: Towards a Technical Justification of Consciousness</a></strong></p>

<p><strong>[5] <a href="https://x.com/SchmidhuberAI/status/1765769164709371978">X</a></strong></p>]]></content><author><name>Do-Hyeon Lee</name></author><category term="AI" /><category term="Consciousness" /><category term="World Models" /><category term="Predictive Coding" /><summary type="html"><![CDATA[Schmidhuber and Conscious Machine]]></summary></entry><entry><title type="html">Mathematician of mind</title><link href="http://localhost:4000/Mathematician-of-Mind/" rel="alternate" type="text/html" title="Mathematician of mind" /><published>2023-12-28T00:00:00+09:00</published><updated>2023-12-28T00:00:00+09:00</updated><id>http://localhost:4000/Mathematician%20of%20Mind</id><content type="html" xml:base="http://localhost:4000/Mathematician-of-Mind/"><![CDATA[<h1 id="mathematician-for-mind">Mathematician for Mind</h1>

<h3 id="after-translating-the-hidden-spring-written-by-mark-solms-into-korean">After translating <em>The Hidden Spring</em>, written by Mark Solms into Korean</h3>

<p>Around the age of 9, my mother was quite shaken after a meeting with my homeroom teacher. She learned that I was showing clear symptoms of ADHD. Despite this, I felt somewhat special, perhaps because I hadn’t received much attention due to my parents’ busy work schedules. As a temporary solution, they sent me to a small Chinese character academy in our neighborhood. Spending most of my days there with the instructor, I would alleviate my loneliness late into the night. Thanks to that experience, I still remember the wise sayings from classics like “Mencius” and “Four Books and Five Classics.”</p>

<p>Upon entering high school, I began to obsess over perfection. The content in textbooks felt insufficient, and I relentlessly pursued various questions. One memory still stands out: during Earth Science class, I realized the textbook lacked a proof of Kepler’s laws and became determined. I resolved to prove these laws and explain them to my teacher and classmates someday. After several sleepless nights, I studied proofs starting with Newtonian mechanics, progressing to Lagrangian and Hamiltonian mechanics<sup><a href="#footnote_1">1</a></sup>. Eventually, I managed to prove all of Kepler’s laws in a single class period (though the chalkboard was beautifully filled, most of my classmates were asleep). Repeated experiences like this led me to crave knowledge beyond what school or academies could offer.</p>

<p>There’s an event that stands out in my memory. It was when I persuaded my teacher and friends to plan a dissection experiment on a sheep’s brain. Convincing my busy academy friends, we carried out the dissection practice in the lab after school. We huddled together in silence, slicing through a sheep’s brain, which was even smaller than a clenched fist. It was nothing short of awe-inspiring. How could our logic and reason, intuition and emotions, joys and sorrows originate from such a small, damp object? I remember having numerous discussions and interviews with our life science teacher at the time. Far from finding answers, I often found myself sinking into deeper pits of inquiry. To broaden my limited perspective, I read books like Sigmund Freud’s “Die Traumdeutung,” Sylvia Nasar’s “A Beautiful Mind,” and Edward O. Wilson’s “Consilience.” Through Freud, I expanded the horizons of my analytical imagination regarding the mind; through Nasar, I glimpsed the tumultuous life of John Nash, a genius mathematician struggling with schizophrenia; and through Wilson, I found resonance with a materialistic approach<sup><a href="#footnote_2">2</a></sup>—embracing neuroscience, neurophysiology, artificial intelligence, and more.</p>

<p>I was fortunate to enroll in a university that allowed me to decide on my major after three semesters. I found it challenging to determine whether I should explore my questions within the realm of physics or life sciences (or perhaps medicine). In my second semester, I interned at a bioinformatics lab, where I became captivated by statistical modeling and big data analysis. During this time, I had the opportunity to take a physics class<sup><a href="#footnote_3">3</a></sup> that was offered for the first time in four years. The class was small, with around five students, and I was the only Korean undergraduate. Struggling with the intense physical concepts, I began to dream of new theories about the mind and consciousness. By the end of my one-and-a-half-year grace period, I had decided to major in mathematics.</p>

<p>The reason I chose to major in mathematics was simple. Above all, I believed my questions were closer to philosophy than to science. Therefore, I needed tools and a way of thinking to do science—to create it—rather than the scientific knowledge itself. Additionally, as numerous fields such as neuroscience, psychology, and artificial intelligence deal with the enigma of the mind, I deeply resonated with the necessity of having a fundamental mindset that could comprehend all of these aspects. Entering the mathematics department allowed me to deeply study mathematical thinking and the formal development of theory, while simultaneously equipping me with the qualifications to study the philosophy of the mind as a background for crafting the science of the mind. After studying mathematics, I was surprised to find that philosophical analytical texts felt remarkably comfortable and accessible to me. I became increasingly enchanted by the elegance and simplicity of various arguments in the philosophy of science and psychology. If asked what the most memorable experience during my undergraduate years was, without a doubt, it would be the public lectures I created to introduce the fundamental mathematical forms of the mind and artificial intelligence algorithms, and the philosophical discourse related to them, titled “Mathematics for Artificial Intelligence<sup><a href="#footnote_4">4</a></sup>” and “Philosophy for Artificial Intelligence<sup><a href="#footnote_5">5</a></sup>.” Meanwhile, my bachelor’s thesis was on “A Topological Analysis of the Learning Process in Artificial Neural Networks,” where I developed tools to capture the structural changes<sup><a href="#footnote_6">6</a></sup> occurring in a virtual brain.</p>

<p>As graduation approached, my interest expanded beyond the problems related to the human mind—consciousness, perception, emotion, memory, etc.—to the essential structure and practical applications of technologies based upon it—cybernetics, optimal control theory, decision theory, machine learning, artificial intelligence, and so on. Intriguingly, the deeper my understanding of mathematical forms and philosophical discourse became, the more acutely I felt the uncomfortable realities of technology and the importance of ethical decision-making. Especially in the field of artificial intelligence, where vigorous research is ongoing, I noticed that the majority of approaches not only clashed with the functioning of living organisms<sup><a href="#footnote_7">7</a></sup> but were also actually inefficient<sup><a href="#footnote_8">8</a></sup>. Moreover, I realized that society’s interest lies far more in how these technologies can be meaningfully utilized on the battlefield to gain an advantage, or commercialized in the market to accelerate consumption, than in understanding their mechanisms and considering the ethical implications. This realization only fueled my determination. In seeking the answers to the workings of the mind, I began to analyze the fundamental composition of artificial intelligence and the principles of machine operation. The persistent questions from my youth, in their quest for ultimate understanding of the mind, became a driving force not just for comprehension but for contemplation of the ultimate direction technology should take, inspiring dreams of a better, more advanced humanity.</p>

<p>To seek the formal commonalities between theoretical neuroscience and artificial intelligence technology, I began to delve into the works of renowned professors from abroad. I started with Marcello Massimini’s “Nulla di piu grande” and Giulio Tononi’s “Phi,” moving on to Anil Seth’s “Being You,” Antonio Damasio’s “The Feeling &amp; Knowing,” Nicholas Humphrey’s “The Sentience,” Amaral Shunichi’s “Brain, Mind, Artificial Intelligence,” and Max Tegmark’s “Life 3.0.” As I read through a plethora of books, I imagined the theory of the mind and the mind of the machine. In Korea, Kim Ju-Hwan’s “Inner Communication” and the “Hypnosis Bible” by Song Kang-Myun and An Min-Sook also proved to be of great help. Most of these books referred to Karl Friston’s Free Energy Principle or Active Inference in the field of theoretical neuroscience. Professor Friston was certainly a prominent figure in neuroscience/medicine, but, astonishingly, he was also well-versed in mathematics<sup><a href="#footnote_9">9</a></sup> and physics<sup><a href="#footnote_10">10</a></sup>, and furthermore, he possessed deep insights into various engineering<sup><a href="#footnote_11">11</a></sup> approaches. In fact, through several papers, I became convinced that his theory could serve as an elegant and clear foundational framework that analytically elucidates the relationship between body, mind, and action.</p>

<p>Dreaming of a systematic understanding of the mind and complete liberation from the questions that have followed me since childhood, and at the same time, envisioning the advent of more efficient and socially responsible machines, I am committed to realizing my beliefs. This work is part of that effort. By chance, I came into contact with Jang Hyun-woo, president of the Korean Association for the Consciousness Sciences(KACS), who is currently a doctoral student in neuroscience, and learned of new translation works<sup><a href="#footnote_12">12</a></sup>. Moreover, I was excited about the opportunity to participate in translating a work by Giulio Tononi, whose book “Phi” I had enjoyed in the past, especially since it was being translated by the psychiatrist Ryeo Won-gi, who I admired. Ultimately, I wanted to be involved because the book deals with the challenging and personally significant issue of consciousness from the perspective of active inference. Although I lack expertise in neurophysiology or clinical medicine, I am confident in my mathematical, physical, and computer science knowledge based on active inference, so I took a chance and asked for understanding, hoping it would not be presumptuous. Fortunately, they graciously accepted the co-translation offer, and I found it rewarding to help with the translation during my spare time after work and on weekends. As both doctors had already translated the draft so well, it was easy to make revisions, check for typos, and adjust the tone of the translation. I sincerely thank Ryeo Won-gi and Jang Hyun-woo for their greater passion and determination in response to my infrequent feedback and complicated answers. It was a happy time, allowing me to gain an unforgettable and valuable experience.</p>

<p>Meanwhile, I am currently creating and managing various cultures that dream of the future of consciousness science and artificial intelligence. Participating in an internship program at the Active Inference Institute, the largest community related to active inference, I became the first Korean to undertake the Ontology project, translating the core terms of the Free Energy Principle and Active Inference. Recently, I have corresponded with Professor Karl Friston in the fields of Neural Computation and Optimal Control Theory, which has seriously prompted me to prepare for the option of studying abroad. Additionally, through the Korean Association for the Consciousness Science, I planned the “Brain-Mind-Behavior” initiative, which carries the following manifesto. This initiative consists of three main activities: a book reading group, a theoretical consciousness science group, and a paper reading group. The theoretical consciousness science group aims to deeply study the theory of active inference. Through this, we aim to study the core themes of body, mind, and action, imagine the potential for development with other fields including artificial intelligence, and hope to initiate the driving force that dreams of a better humanity, deeply contemplating the ultimate direction that technology should take, centered in Korea.</p>

<blockquote>
  <p>conscious activity are a key feature that allows us to distinguish ourselves from other species.
However, the nature and mechanisms of consciousness remain an unresolved, complex mystery.
Our goal is to solve this problem using scientific methods and to understand the essence of the mind-brain-behavior nexus.</p>

  <p>Our efforts are carried out through a multidisciplinary approach:
scholars and experts from diverse fields such as mathematics/philosophy, physics/psychology, computer science/neuroscience come together to analyze and deconstruct the fundamental aspects of consciousness.
The analyses produced are then related to the questions of biology and philosophy.</p>

  <p>We emphasize the importance of consciousness research and aim to expand our social impact through ongoing meetings and content sharing.
Furthermore, in the process of achieving our goals, we aspire to contribute to scientific research and ethical issues related to hypnosis, augmented reality, future artificial intelligence, animal consciousness, and artificial sentient entities.</p>
</blockquote>

<p><a name="footnote_1">1</a>: I only came to realize much later that it was part of the “Classical Mechanics” subject in the university physics curriculum.<br />
<a name="footnote_2">2</a>: Edward O. Wilson’s “Consilience,” Chapter 6 “The Mind”.<br />
<a name="footnote_3">3</a>: Professor Seung-Hwan Kim, the inaugural president of the Korean Computational Neuroscience Society, on “Nonlinear Dynamics and Chaos Theory.”
I remember spending time reading Erwin Schrödinger’s “What is Life?” and Jacques Monod’s “Chance and Necessity.”<br />
<a name="footnote_4">4</a>: <a href="https://youtube.com/playlist?list=PLfWS6_PaCSutSAC7Vu8VHS2uc594cQigv&amp;si=Q2cpP5ExvW84vQM2">“Mathematics for AI” link</a><br />
<a name="footnote_5">5</a>: <a href="https://youtube.com/playlist?list=PLfWS6_PaCSusXxpOxUSs6ONTln3pHWALy&amp;si=fidIXxTUlk5xvCXF">“Philosophy for AI” link</a><br />
<a name="footnote_6">6</a>: Here, “structure” refers to the macroscopic topological structure. Have you ever heard that a donut is homeomorphic to a mug?<br />
<a name="footnote_7">7</a>: Of course, it is possible that the operating principles of living organisms and artificial intelligence algorithms do not necessarily need to be aligned. However, I want to emphasize that there are very few attempts to analyze the relationship between the two and to find a better direction. See Chapter 1 of Professor Geoffrey Hinton’s “The Forward-Forward Algorithm: Some Preliminary Investigations” for reference.<br />
<a name="footnote_8">8</a>:
Refer to Amaral Shunichi’s “Brain, Mind, Artificial Intelligence.” A computer consumes 175 watts per hour, a light bulb 60 watts, but the human brain uses only about 12 watts.<br />
<a name="footnote_9">9</a>: Information theory, statistics, information geometry, and more.<br />
<a name="footnote_10">10</a>: Classical mechanics, statistical mechanics and thermodynamics, and the arguments of E. T. Jaynes, among others.<br />
<a name="footnote_11">11</a>: Statistical learning theory and reinforcement learning theory in the field of machine learning, along with cybernetics and optimal control theory, among others.<br />
<a name="footnote_12">12</a>: President Jang Hyun-woo has previously translated Euan Squires’ “The Conscious Mind in the Physical World,” Antti Revonsuo’s “Foundations of Consciousness,” Gerald Edelman’s “A Universe of Consciousness,” and Susan Blackmore’s “Conversations on Consciousness.” I have read all of these works, and they have been immensely helpful in understanding the key themes related to consciousness.</p>]]></content><author><name>Do-Hyeon Lee</name></author><category term="Translation" /><category term="Consciousness" /><category term="AI" /><category term="Beliefs" /><summary type="html"><![CDATA[Mathematician for Mind]]></summary></entry><entry><title type="html">Embodied cognition</title><link href="http://localhost:4000/Embodied-Cognition/" rel="alternate" type="text/html" title="Embodied cognition" /><published>2023-12-20T00:00:00+09:00</published><updated>2023-12-20T00:00:00+09:00</updated><id>http://localhost:4000/Embodied%20Cognition</id><content type="html" xml:base="http://localhost:4000/Embodied-Cognition/"><![CDATA[<h1 id="체화된-인지">체화된 인지</h1>

<h5 id="체화된-인지란">체화된 인지란?</h5>

<ul>
  <li>참고자료: [Phil, 1] <a href="https://s-space.snu.ac.kr/bitstream/10371/75876/1/02.%20%EC%9D%B4%EC%A0%95%EB%AA%A8.pdf">‘체화된 인지(Embodied Cognition)’ 접근과 학문 간 융합</a></li>
</ul>

<h2 id="1-20세기의-인지과학">1 20세기의 인지과학</h2>

<blockquote>
  <p>“마음에 대한 철학적 탐구 이어 받기”</p>
</blockquote>

<h3 id="11-인지과학-탄생-이전">1.1 인지과학 탄생 이전</h3>

<p>16, 17세기 유럽의 과학혁명 이후, 모학문인 철학으로부터 각기 독립하여 여러 과학 분야를 형성하게 되었다. 이러한 흐름을 이어 받아 19세기의 학자들 중에는 마음의 문제까지도 직관적 논리적 분석을 넘어 객관적 실험 중심의 경험 과학적 근거에 의하여 탐구할 수 있는 가능성을 모색하려는 이들이 있었다.</p>

<ul>
  <li>1870년대 - 빌헬름 분트(Wilhelm Wundt), 심리학을 독립된 경험과학으로 출발; ‘실험 생리적 심리학’
→ 약 30년 간 심리학은 마음의 주관적 체험으로써의 의식의 분석 측면을 강조함.
→ 의식 내용에 대한 개인의 주관적 보고를 분석하는 방법의 체계화에 초점을 둠.
→ 철학의 전통인 “직관적 내성법Introspection”을 과학적 심리학의 방법론으로 가다듬어 체계화함.
; <strong>구조주의(구성주의)</strong> + <strong>내성법의 방법론</strong></li>
  <li>20세기 초 - 왓슨(Watson, J. B.), 구조주의 비판 및 경험주의적 행동주의 심리학의 틀 출발
→ 구조주의는 실증주의적 객관적 과학의 틀에서 벗어난 것이라고 비판함.
→ 철학의 논리실증주의에 강하게 영향을 받아, 객관적으로 관찰 가능한 것만 다루고자 함.
→ 심성적mental 개념들은 배척, 행동만을 대상으로 삼음.
→ 조건형성(Conditioning) 과정으로 동물과 인간의 행동을 기술하려 함.
→스키너(B. F. Skinner)는 인간 언어와 사고 영역까지 설명하려고 함.
; <strong>행동주의</strong> + <strong>조건형성의 방법론</strong> (~1950)</li>
  <li>1950년대 후반 - 인지혁명cognitive revolution(a.k.a. 20세기의 과학혁명)
→ 행동주의가 심리학에서 마음 개념을 축출한 것을 비판함.
→ 인간 자신, 동물, 컴퓨터, 인간문화체계 등에 대한 새로운 패러다임
; <strong>고전적 인지주의Cognitivism</strong> + <strong>정보처리적 접근방식</strong> ← “인지과학”의 발생
    <p align="center">
  <img src="/assets/images/231220/1.png" />
  </p>
  </li>
</ul>

<h3 id="12-인지주의-인지과학의-특성과-의의">1.2 인지주의, 인지과학의 특성과 의의</h3>

<p align="center">
    <img src="/assets/images/231220/2.png" /> 
</p>

<ul>
  <li>인지주의 패러다임: ‘마음’ $\sim$ ‘컴퓨터’ $\sim$ ‘정보처리 체계(Information Processing Paradigm: IPS)’
⇒ 인간과 동물의 마음에서 그리고 컴퓨터에서 각종 정보처리가 어떻게 일어나며, 그러한 정보처리를 통해서 마음또는 지知(능)가 어떻게 가능하게 되고 구현되는가?
→ “知란 마음의 작용에서 비롯되는 것이므로 인지과학은 마음의 과학(Science of Mind)이 된다.”
    <ol>
      <li>마음(Mind), 2) 두뇌(Brain), 3) 컴퓨터(Computer), 4) 인공물(Artifact)
<strong>주요 특징들</strong></li>
      <li>‘마음’ $\sim$ ‘컴퓨터’ $\sim$ ‘정보처리 체계(Information Processing Paradigm: IPS)’</li>
      <li>마음의 <strong>과정</strong>은 정보의 처리, 변환이라는 <strong>계산주의적 관점Computationalism</strong>이다.</li>
      <li>마음의 <strong>내용</strong>은 지향적 대상의 표상으로 이루어진다는 <strong>표상주의Representationalism</strong>다.</li>
      <li>마음은 <strong>뇌</strong>의 신경적 상태에 기초한다는 <strong>신경과학적 기반</strong>의 강조이다. (그러나 HW/SW의 분리)</li>
      <li>마음의 <strong>탐구</strong>는 여러 학문들의 수렴에 의하여 가능하다; <strong>수렴(융합)적</strong> 접근의 강조이다.</li>
    </ol>
  </li>
</ul>

<h3 id="13-인지과학과-학문-간-연결-수렴-융합">1.3 인지과학과 학문 간 연결, 수렴, 융합</h3>

<p>→ <strong>인공지능, 인지심리학, 철학, 언어학, 인지신경과학</strong></p>

<p align="center">
    <img src="/assets/images/231220/3.png" /> 
</p>
<h2 id="2-인지과학-틀의-변천-역사">2 인지과학 틀의 변천 역사</h2>

<p>1980년대 중반부터 ‘마음’에 대한 개념적 재구성 작업이 진행됨.</p>

<h3 id="21-이정모의-분류">2.1 <strong>이정모의 분류</strong></h3>

<ul>
  <li>1단계; 1950년대~1980년대 전반
    <ul>
      <li>마음을 제거하였던 행동주의의 반심성주의(Anti-Mentalism)에서 탈피</li>
      <li>마음을 디지털 컴퓨터 유추에 바탕을 둔 <strong>물리적 기호 체계</strong>(Physical Symbol System)로 개념화</li>
    </ul>
  </li>
  <li>2단계; 1980년대 이래
    <ul>
      <li>컴퓨터 은유 중심의 고전적 정보처리 접근의 이론적 개념화에 한계를 느낌.</li>
      <li>뇌 은유 중심의 <strong>신경망 연결주의</strong> 접근에 의하여 상징이하(Subsymbolic) 체계의 계산주의를 제시함.</li>
    </ul>
  </li>
  <li>3단계; 1990년대 이후
    <ul>
      <li>뇌 영상 기법을 비롯한 <strong>인지신경과학</strong> 연구기법의 급격한 발전으로 뇌 기능의 중요성을 재발견함.</li>
      <li>인지과학의 마음에 대한 접근을 신경과학의 기초 위에 놓으려고 했다.</li>
    </ul>
  </li>
  <li>4단계; 1980년대 후반, 21세기 초
    <ul>
      <li><strong>몸과 환경 맥락의 역할을 강조하는 변혁</strong></li>
      <li>인간의 마음이 물리적, 사회적 환경 맥락에 적응하는 순간 순간적 상호작용 신체적 행위 활동 상에서 비로소 존재하게 되는 인지다.</li>
    </ul>
  </li>
</ul>

<h3 id="22-evan-thompson의-분류">2.2 <strong>Evan Thompson의 분류</strong></h3>

<ul>
  <li>1단계 ← 인지주의(Cognitivism)</li>
  <li>2단계 ← 연결주의(Connectionism) (컴퓨터→뇌의 변화는 ‘아래로의 끌음downwards pull’에 해당)</li>
  <li>3단계 ← 체화된 동역학주의(Embodied Dynamicism) (뇌→몸과 환경의 변화는 ‘밖으로의 끌음outwards pull’에 해당)</li>
</ul>

<h3 id="23-최후의-입장은-체화된-인지">2.3 최후의 입장은? <strong>체화된 인지</strong></h3>

<ul>
  <li>데카르트적 심신 이원론, 고전적 인지주의, 환원주의적 유물론에 대해 비판적 설명 틀을 전개함.</li>
  <li>모두 마음의 본질과 특성을 제대로 설명할 수 없으며, 마음을 뇌 내부의 신경적 상태만으로 환원하는 것은 부족한 개념화라고 주장함.</li>
  <li>뇌-신체-세상이 연결된 통합체 상의 현상으로 개념화해야 적절하다고 주장함.</li>
</ul>

<h2 id="3-체화된-인지마음embodied-cognitionmind-접근">3 체화된 인지/마음(embodied cognition/mind) 접근</h2>

<h3 id="31-체화된embodied-인지-연장된extended-마음">3.1 체화된(Embodied) 인지, 연장된(Extended) 마음</h3>

<ul>
  <li>전통적인 데카르트적 존재론/인식론에 기초한 마음(Mind)의 개념으로부터 탈피하여, 구체적인 몸이라는 실체를 가지고 환경과의 상호작용 속에서 출현하는 인간의 적응 ‘행위’로서의 ‘마음’의 관점으로 전환하는 움직임.</li>
  <li>연장된 마음 가설(HEM/HEC: Hypothesis of Extended Mind/Cognition, Andy Clark &amp; David Chalmers 1998)</li>
</ul>

<p>→ 미시적, 신경적 또는 생물적 단위 수준에서 모든 것을 설명하려는 연결주의와 같은 낮은 설명 수준의 접근, 그보다 한 수준 위에서 명제 중심으로 논리적 체계에 의해 설명하려는 고전적 인지주의의 정보처리 접근이 지니는 제한점을 벗어나려 한다.</p>

<p>→ 환경과는 독립적으로 한 개인 마음 내부에서 일어나는 정보의 인지적 표상이나 처리가 아니라, 환경과 괴리될 수 없이 환경-몸-뇌가 하나의 통합적 단위를 이루는 바탕 위에서 행위를 통하여 구현되는 활동으로서의 마음을 설명하려고 한다.</p>

<blockquote>
  <p>“마음은 뇌 속에서 일어나는 신경적 상태나 과정이라고 하기보다는 신경적 기능구조인 뇌, 뇌 이외의 몸, 그리고 환경의 3자가 괴리되지 않은 채 하나의 단위로 작용하는 통합체(Nexus) 상에서 이뤄지는 행위 중심으로 재개념화되어야 한다고 본다.”</p>
</blockquote>

<p>→ 본질적으로 데카르트적 이원론에 바탕을 둔 존재론과 그에 따른 인식론으로부터 벗어나자는 탈 데카르트적 운동의 일환이라고 볼 수 있으며, 일찍이 17세기 B. Spinoza에 의해 이루어졌다. Spinoza 이후 몸에 대한 강조는 유럽의 현상학적 철학자들에 의하여 주로 이어져 왔다. 베르그송-메를로 퐁티 등의 논의에서는 뇌와 독립적으로 존재하는 심리적 속성의 가능성이 논의되고, 몸과 마음과 환경이 하나의 단위를 이룬다. 몸이 환경의 세상과 일체가 되어 적응하는 과정에서 몸의 행위 하나하나가 마음을 구성한다고 보는 것이다.</p>

<ul>
  <li>인지심리학자 M. Wilson: 마음, 인지가 몸에 근거하고 있다</li>
  <li>Gomila, Calvo: 체화보다는 상호작용성(interactivism)과 역동성(dynamicism)이 더 핵심이다.</li>
</ul>

<aside>
💡 *행동주의심리학이 마음을 심리학에서 축출하였고, 고전적 인지주의가 그 마음을 인지과학에 되찾아주었지만 뇌의 역할을 무시하였고, 인지신경심리학이 마음을 다시 뇌 속으로 넣어주었지만 환경(맥락)의 역할을 무시하였다면, 이제 제3의 대안적 관점인 ‘체화된 인지’ 접근을 통하여 그 뇌를 몸으로, 그리고 다시 그 몸을 환경으로 통합시키는 작업을 하여야 한다고 볼 수 있다.*

</aside>

<h3 id="32-체화된-마음과-인공물">3.2 체화된 마음과 인공물</h3>

<p>→ 몸과 괴리되지 않은 마음이 몸을 통하여 환경에 공간적 확장, 연장의 특성을 지닌 역동적인 활동에 존재하는 것으로 개념화한다면? 인간 마음과 각종 인공물의 공진화 역사와 미래의 가능성에 대한 고려이다.</p>

<p>인간 마음과 인공물 사이의 경계가 무너지고 인간과 인공물과의 상호작용 활동 특성을 중심으로 인간의 존재론적 재구성의 필요성이 절실하여지는 미래 시점에서, 인간의 마음, 몸, 활동, 환경 인공물 사이의 관계성을 묻는 철학의 ‘체화된 인지’ 틀은 미래 학문과 테크놀로지의 개념적 재구성에 중요한 이론적 바탕을 제공하리라 본다.</p>

<h3 id="33-체화된-인지-접근의-문제점">3.3 체화된 인지 접근의 문제점</h3>

<ol>
  <li>과학적 패러다임의 측면
    <ul>
      <li>인간(몸)－환경의 상호작용 측면을 어떻게 경험과학적 탐구의 면면으로 객관화하는가?</li>
      <li>기존의 인지주의 접근이 성공한 설명적 측면보다 더 좋고 체계적인 기술과 설명을 제공하여야 한다는 과제도 남
는다.</li>
    </ul>
  </li>
  <li>개념적 측면
    <ul>
      <li>Adams &amp; Aizawa(2008, 2010) 등이 제기하는 이론적 비판의 문제점을 해결해야 하는 과제도 있다.
        <ol>
          <li>등가성 원리: HEM/HEC는 환경이 과연 뇌와 동등한 등가의 인지시스템이 될 수 있는가?</li>
          <li>결합 논변: 환경의 물질적 대상은 뇌와 하나의 결합체를 이룰 수 없다!
↔ 전통적인 물질－정신, 안과 밖이라는 이분법적 범주적 생각을 벗어나지 못하고 있다고 비판도 있다.</li>
        </ol>
        <aside>
  💡 인지 과정 여부를 결정짓는 관건은 안과 밖의 위치(location)나, 뇌 대 인공물의 물질적 유사성 여부가 아니라, 바로 **과정의 기능성(functionality)**이다. …
  “체화된 인지 접근은 인간 존재, 마음, 몸, 환경(인공물 포함)의 역할, 표상, 지향성, 인지시스템, 인지과정, 인과성, 인간－인공물의 상호작용 등의 여러 주제에 대한 탐구에서 전통적 개념을 벗어나는 발상의 전환이 이루어져야 함을 강하게 호소하고 있는 것이라고 본다.”
  </aside>
      </li>
    </ul>
  </li>
</ol>

<h3 id="34-체화된-인지-접근과-학문-간-융합">3.4 체화된 인지 접근과 학문 간 융합</h3>

<ul>
  <li>몸-마음-생명에 대한 통합적 틀로의 발상의 전환이 이루어져야 함을 요구하는 개념적 전환.</li>
</ul>

<aside>
💡 인간(동물 또는 로봇)의 몸과 환경이 하나로 어우러진 신체적 활동에서
마음, 인지(동물과 로봇의 경우에는 지능)가 어떻게 발생되는가?

</aside>

<p><br /></p>

<h1 id="참고자료">참고자료</h1>

<hr />

<p><strong>Philosophy</strong></p>

<ul>
  <li>[1] <a href="https://s-space.snu.ac.kr/bitstream/10371/75876/1/02.%20%EC%9D%B4%EC%A0%95%EB%AA%A8.pdf">‘체화된 인지(Embodied Cognition)’ 접근과 학문 간 융합</a>
    <ul>
      <li>이정모(2010), ‘체화된 인지(Embodied Cognition)’ 접근과 학문 간 융합, 철학사상.</li>
    </ul>
  </li>
</ul>

<p><strong>Robotics</strong></p>

<ul>
  <li>[1] <a href="https://arxiv.org/pdf/1801.04819.pdf">Robots as powerful allies for the study of embodied cognition from the bottom up</a>
    <ul>
      <li>Hoffmann, M. &amp; Pfeifer, R. (2018), Robots as powerful allies for the study of embodied cognition from the bottom up, in A. Newen, L. de Bruin; &amp; S. Gallagher, ed., ‘The Oxford Handbook 4e Cognition’, Oxford University Press, pp. 841-861.</li>
    </ul>
  </li>
  <li>[2] <a href="https://d1wqtxts1xzle7.cloudfront.net/64936166/Lara_et_al_2018_Embodied_Cognitive_Robotics_and_the_learning_of_sensorimotor_schemes-libre.pdf?1605383929=&amp;response-content-disposition=inline%3B+filename%3DEmbodied_Cognitive_Robotics_and_the_lear.pdf&amp;Expires=1703039325&amp;Signature=bubgM3q5K1C4LL7Qqkt0xw7CK8RIVEC0gGMtmkuL5tKp3AqvgaScZ~8-5OzaU0aqarwlwQqQwMSfc05LAyxHYPTO5Trr0hDqFCRx~~RPdPQ1oDOghkAc6Qc-VzlaLiRX2cmiGzr3VroHdwOtlGEWFqJs5FCNhv4yVtsAOv7tu3yJa0Qj4ajJAdUyPPfUnNEq3AJ4ZZkOr~Y~6zqBSzKgw-djTlolXAgjBWHLYlG3Cd3ayiRAbqo9QdnJM4oiS1Csaw6lzjxTBAIwOZT553uIUrxlDnOSsoZWP~DH9zRYiSO9QTMoHS3qQszl1i6ooee87NBa0AU4d4jD4sSwGkDcNQ__&amp;Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA">Embodied Cognitive Robotics and the learning of sensorimotor schemes</a>
    <ul>
      <li>Lara B, Astorga D, Mendoza-Bock E, Pardo M, Escobar E, Ciria A. Embodied Cognitive Robotics and the learning of sensorimotor schemes. <em>Adaptive Behavior</em>. 2018;26(5):225-238. doi:<a href="https://doi.org/10.1177/1059712318780679">10.1177/1059712318780679</a></li>
    </ul>
  </li>
  <li>[3] <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10526461/pdf/brainsci-13-01316.pdf">From Brain Models to Robotic Embodied Cognition: How Does Biological Plausibility Inform Neuromorphic Systems?</a></li>
</ul>]]></content><author><name>Do-Hyeon Lee</name></author><category term="Philosophy of Mind" /><category term="Cognitive Science" /><summary type="html"><![CDATA[체화된 인지]]></summary></entry><entry><title type="html">Ai, robot, and consciousness</title><link href="http://localhost:4000/AI,-Robot,-and-Consciousness/" rel="alternate" type="text/html" title="Ai, robot, and consciousness" /><published>2023-12-14T00:00:00+09:00</published><updated>2023-12-14T00:00:00+09:00</updated><id>http://localhost:4000/AI,%20Robot,%20and%20Consciousness</id><content type="html" xml:base="http://localhost:4000/AI,-Robot,-and-Consciousness/"><![CDATA[<h3 id="세상에-대한-거울">세상에 대한 거울</h3>

<p>인간의 마음은 우주와 같아서, 우주와 두뇌를 나란히 두면 하나는 다른 하나를 담아낸다. 우리의 두뇌는 우주를 담고, 우주는 두뇌를 담는다. 그런데, 두뇌는 우주를 담고, 우주는 두뇌를 담고, 두뇌는 우주를 담고, 우주는 두뇌를 담고, … 인간의 마음은 세상에 대한 거울인가?</p>

<h3 id="intro">Intro</h3>

<p>2022년, 구글의 챗봇 서비스인 LaMDA의 개발자 <a href="https://www.washingtonpost.com/technology/2022/06/11/google-ai-lamda-blake-lemoine/">Blake Lemoine은 자신이 개발한 SW가 느낌을 가진다고 주장</a>했다. 이후, 당시 CEO인 Sundar Pichai는 그가 기밀을 유포했다는 점을 들어 해고했으며, 그가 해당 SW를 충분히 이해하지 못했다고 표현했다. 그런데, AMCS에 따르면 우리는 ‘인간의 마음’도 거의 이해하지 못했다. 이러한 이유로 의식 연구의 필요성이 커지고 있다.</p>

<p>2023년 4월, <a href="https://www.bbc.com/news/technology-65401783">BBC의 테크 전문 에디터 <strong>Zoe Kleinman</strong>는 인공지능 연구자들이 의식을 연구할 필요성이 있다고 경고하는 글</a>을 발표했다. 그는 세계적인 기술 부호 Elon Musk가 추가적인 법적 조치가 마련되기 전까지 AI 개발을 보류해야 한다는 공동 서명을 작성했다는 점, 수리의식과학학술회(AMCS)가 책임질 수 있는 인공지능 개발을 위해 의식 연구를 포함시켜야 한다는 공개 서한을 발표했다는 점 등을 강조한다. 윤리적이고 책임질 수 있는 미래를 위해 의식 연구가 더욱 활성화되고 인공지능 연구와 더 강하게 상호작용해야 한다는 취지이다.</p>

<p>Nature 기자인 Mariana Lenharo는 2023년 8월 “<a href="https://www.nature.com/articles/d41586-023-02684-5">AI가 의식적이 된다면, 연구자들이 알아야할 점</a>”, 2023년 12월 “<a href="https://www.nature.com/articles/d41586-023-04047-6">AI 의식: 과학자들은 우리가 시급히 답이 필요하다고 말한다</a>” 등 인공지능의 의식에 대한 법적, 윤리적 제도 마련과 그에 따른 의식 연구의 필요성을 역설하는 글을 꾸준히 작성하고 있다.<br />
<br /></p>

<h1 id="1-인공지능과-로봇">1. 인공지능과 로봇</h1>

<p>인공지능(Artificial Intelligence)은 인간의 문제 해결 능력을 컴퓨터 SW로 모델링하여 실제 세상의 문제를 해결하는 분야이다. 2023년 인공지능 기술은 세상을 놀라게 했는데, 큰 주제로는 대규모 언어 모델(Large Language Model;LLM)을 비롯한 생성형 인공지능(Generative AI)가 있다.</p>

<h2 id="11-ai">1.1 AI</h2>

<h3 id="llm">LLM</h3>

<p>그 중 사람들에게 가장 큰 충격을 준 서비스를 꼽자면, 단연 오픈 AI(Open AI)의 ChatGPT-3.5, 4가 있다. ChatGPT는 대규모 언어 데이터를 트랜스포머(Transformer) 아키텍처를 활용해 학습한 모델로, 대화형 챗봇 형태의 서비스를 제공한다. 현재 최신 버전인 ChatGPT-4는 단순히 글 형식 뿐만 아니라, 이미지, 동영상, pdf, 프로그램 코드 등의 다양한 형태를 입력받고 생성할 수 있다. 이러한 Multi-Modality는 ChatGPT가 지닌 무한한 가능성을 시사한다.</p>

<p align="center">
    <img src="/assets/images/231214/1.png" />
</p>

<p>이처럼, 대규모 언어 모델의 가능성을 살펴본 슈퍼 테크 기업들은 대화형 검색 서비스 사업에 뛰어들었다. Meta(구 페이스북)의 Llama2, Claude2, 구글의 Bard까지 수많은 대화형 검색 서비스 사업이 시작되고 있다.</p>

<p align="center">
    <img src="/assets/images/231214/2.png" />
</p>

<h3 id="text2image-video">Text2Image, Video</h3>

<p>OpenAI는 또한 Dall-e와 같은 이미지 생성 서비스도 제공하고 있다. 디퓨전 모델 등을 개발한 Runway ML부터, Pika Labs와 같이 프롬프트 기반 동영상 생성 서비스도 등장했으며 큰 투자를 받고 성장하고 있다. 최근엔 인공지능 서비스 기반의 제작 툴 시장에 급격히 성장하고 있으며, 최초의 AI 영화제가 열리기도 하였다. Pika Labs는 창업 반년 만에 600억에 달하는 투자유치에 성공했다.</p>

<p><img src="https://youtu.be/6b10jGNNbXQ?si=JRuw_I25uT-VZMnY" alt="PikaLabs" /></p>

<h2 id="12-robots">1.2 Robots</h2>

<h3 id="robot">Robot</h3>

<p>그 중 로봇 기술은 다른 AI에 비해 현실적이고, 물리적인 문제를 해결하는 데에 초점을 두고 있다. 로봇은 일반적으로 원하는 동작을 문제없이 수행하고 자연스럽게 제어하는 것조차 큰 어려움이 있었다. 그러나, 강화학습(Reinforcement Learning) 기술을 비롯한 대규모 학습 모델을 바탕으로 이 어려움을 극복했다. Tesla의 일론 머스크(Elon Musk) 회장은 인간과 유사한 휴머노이드 형태의 로봇을 $2,000 정도의 가격으로 보급하는 것을 꿈꾼다고 밝힌 적이 있다. 실제 연말에 발표한 Optimus gen2는 불과 1년만에 자연스럽게 걷기 시작했고, 뛰어난 손 모델이 탑재되어 계란을 집을 수 있을만큼 섬세한 조작이 가능해졌다.<br />
<img src="https://youtu.be/cpraXaw7dyc?si=iACTBTgiY39PRZOf" alt="Optimus Gen2" /></p>

<p>이와 함께, Unitree의 Go2, B2, H1은 충격적으로 유연하고 뛰어나게 작동하는 로봇의 모습을 보여준다. 심지어 사람이 강하게 밀치거나 의도적인 방해를 가하더라도 성공적으로 수행한다. 바퀴나 트랙 형태의 로봇부터, 족형 로봇이나 보행 로봇까지 다양한 형태의 로봇이 등장하고 있으며, 그들의 운동 수행 방식은 점차 발전하고 있다. 일론 머스크의 꿈에 답하듯이, 수많은 로봇회사들 또한 낮은 제품 가격을 유지하고 있는 추세다.<br />
<img src="https://youtu.be/-0n_MFLKD3M?si=7jNbdD4Z-Q53epDZ" alt="B2" /></p>

<h1 id="2-현대-ai-접근의-한계">2. 현대 AI 접근의 한계</h1>

<h2 id="21-인공지능의-한계">2.1 인공지능의 한계</h2>

<p>인공지능 기술은 수직에 가까운 속도로 성장하고 있다. 특히, AGI(일반 인공지능) 혹은 Human-Level AI(인간 수준 인공지능)에 준하는 기술들이 등장하기 시작했다. 급속도로 발전하는 인공지능 기술의 이면에는 수많은 잠재적 위험들이 도사리고 있다. 이에 따라, 세계적인 신경과학자 Karl Friston이 수석 과학자로 있는 캐나다의 인지 컴퓨팅 기업 Verses AI는 지난 12월 20일 NY Times의 공개 광고면을 활용해 OpenAI에게 공개 서한을 보냈다. 먼저, 그들은 현재 인공지능 기술이 지니고 있는 한계점을 나열했다.</p>

<aside>
👨🏻‍💻 *· Black box problem ← AI 모델의 내부 작동 방식을 확인할 수 없다는 점.*

_· Alignment problem ← AI 모델의 작동 원리를 인간 윤리에 정렬하는 일반적 방법이 없다는 점._

_· Generalizability problem ← AI 모델이 일반화 성능을 달성하기 어렵다는 점._

_· Hallucination problem ← AI 모델이 겪게 되는 환각문제를 해결하기 어렵다는 점._

_· Centralization problem — one corporation owning the AI ← 현재 몇개의 테크기업이 인공지능 기술을 독점하고 있다는 점._

_· Clean data problem ← 완벽히 개인정보를 지우고 학습에 활용할 일반적인 방법이 없다는 점._

_· Energy consumption problem ← 대규모의 데이터를 학습시키는데 엄청난 에너지가 소비된다는 점._

_· Data update problem ← 추가적인 데이터를 바탕으로 업데이트하고자 할 때 재앙적 망각 문제를 해결하기 어렵다는 점._

_· Financial viability problem ← AI가 상업적으로 활용되었을 때 수익의 소유와 관련해 문제의 소지가 있다는 점,._

_· Guardrail problem ← AI가 인간을 뛰어넘었을 때 인간에게 해가 되지 않도록 가드레일을 설계할 필요가 있다는 점._

_· Copyright problem ← 데이터의 소유권과 침해 문제로부터 자유로울 수 없다는 점._

</aside>

<p>그들은 자신의 회사가 지닌 기반 기술(Active Inference 기반의 인지 컴퓨팅 기술, Scaling하는 것을 넘어서서 자연의 지능을 벤치마크로 활용하는 태도 등)을 바탕으로 극복할 수 있다고 주장했다.</p>

<p align="center">
    <img src="/assets/images/231214/3.png" />
</p>

<p>이러한 문제점은 비단 그들이 주장하는 것뿐만 아니라, 인공지능 기술 발전의 핵심이었던 Geoffrey Hinton, Yan LeCun 등의 교수들 스스로도 지적한 바가 있다. 더욱이 Max Tegmark의 Life 3.0, Brian Christian의 The Alignment Problem, Nick Bostrom의 Superintelligence 등에서도 지속적으로 제기된 바가 있다. 실제로, 강화학습만 하더라도 아직까지 많은 문제가 존재하며, 해결해야 할 문제로 (1)Sample Inefficiency, (2)Nice Alternatives, (3)Hard Reward Design, (4)Local Optima, (5)Generalization Issue, (6)Stability &amp; Reproducibility Issue 등이 있다.</p>

<h2 id="22-인지과학적-접근">2.2 인지과학적 접근</h2>

<p>→ 인공지능의 역사</p>

<p>2010년을 이래로 급격히 발전한 인공지능 기술의 역사를 돌이켜보면, 핵심적인 과학 원리나 전신이 되는 사이버네틱스와의 관련성이 드러나는 경우가 많지 않다. 결과적으로 보자면, 현대의 인공지능 기술은 근대의 인지주의(Cognitivism)적 접근 방식에서 발전해 연결주의적 관점과 최근에 이르러 체화된 동역학주의의 이론체계가 기술로 구현된 것에 지나지 않는다. 쟝 피에르 뒤피가 지적했듯이 과학기술은 생각보다 합리적으로 발전하지도, 자체적으로 성장하지도 않는다. 오히려 과학기술은 가만히 냅두면 퇴보하며, 깊은 철학적 성찰과 반추없이는 불필요한 낭비를 줄이기란 불가능에 가깝다.</p>

<ol>
  <li><strong>Evan Thompson의 분류</strong>
    <ul>
      <li>1단계 ← 인지주의(Cognitivism): 1950년대~1980년대 전반
        <ul>
          <li>마음을 제거하였던 행동주의의 반심성주의(Anti-Mentalism)에서 탈피</li>
          <li>마음을 디지털 컴퓨터 유추에 바탕을 둔 <strong>물리적 기호 체계</strong>(Physical Symbol System)로 개념화</li>
        </ul>
      </li>
      <li>2단계 ← 연결주의(Connectionism) (컴퓨터→뇌의 변화는 ‘아래로의 끌음downwards pull’에 해당): 1980년대 이래
        <ul>
          <li>컴퓨터 은유 중심의 고전적 정보처리 접근의 이론적 개념화에 한계를 느낌.</li>
          <li>뇌 은유 중심의 <strong>신경망 연결주의</strong> 접근에 의하여 상징이하(Subsymbolic) 체계의 계산주의를 제시함.</li>
        </ul>
      </li>
      <li>3단계 ← 체화된 동역학주의(Embodied Dynamicism) (뇌→몸과 환경의 변화는 ‘밖으로의 끌음outwards pull’에 해당):
        <ul>
          <li>1990년대 이후
            <ul>
              <li>뇌 영상 기법을 비롯한 <strong>인지신경과학</strong> 연구기법의 급격한 발전으로 뇌 기능의 중요성을 재발견함.</li>
              <li>인지과학의 마음에 대한 접근을 신경과학의 기초 위에 놓으려고 했다.</li>
            </ul>
          </li>
          <li>1980년대 후반, 21세기 초
            <ul>
              <li><strong>몸과 환경 맥락의 역할을 강조하는 변혁</strong></li>
              <li>인간의 마음이 물리적, 사회적 환경 맥락에 적응하는 순간 순간적 상호작용 신체적 행위 활동 상에서 비로소 존재하게 되는 인지다.</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>최후의 입장은? <strong>체화된 인지</strong>
    <ul>
      <li>데카르트적 심신 이원론, 고전적 인지주의, 환원주의적 유물론에 대해 비판적 설명 틀을 전개함.</li>
      <li>모두 마음의 본질과 특성을 제대로 설명할 수 없으며, 마음을 뇌 내부의 신경적 상태만으로 환원하는 것은 부족한 개념화라고 주장함.</li>
      <li>뇌-신체-세상이 연결된 통합체 상의 현상으로 개념화해야 적절하다고 주장함.</li>
    </ul>
  </li>
</ol>

<p>최근들어 이론 신경과학의 자유 에너지 원리Free Energy Principle와 능동 추론Active Inference의 규범 이론이 자리를 잡고, 관련 역학 이론 체계인 베이즈주의적 역학Bayesian Mechanics이 정립되었다. 이러한 발전에 따라, 수학적 최적화 이론과 인지 과학의 이론들 사이의 관계성이 널리 알려지기 시작했다. 실제로, 인공지능의 발전에 크게 힘쓴 Stanford AI 대학원의 Fei-Fei Li 교수의 Interactive and Embodied Learning 수업에서는 보충 자료, 정규 수업 자료로 채택하고 있다.
인공지능이 현재 겪고 있는 문제를 해결하고, 더욱 발전시키기 위해서는 <strong>인지신경과학</strong>과 <strong>체화된 인지과학</strong>의 관점이 절실할 수 밖에 없다. 인공지능 기술은 산업적 문제로부터의 피드백 이상의 과학적 기반이 없기 때문이다. 물론 인지신경과학의 원리를 어떻게 인공지능 기술에 접목할 지는 어려운 도전이겠지만, 별다른 선택지가 없어보인다. 보다 원리적인 관점에서 보면, 인공지능의 과학적 토대는 인공 지능; 기계 학습을 비롯한 <strong>수학적 최적화 이론</strong>과 함께 자연 지능, 특히 몸-마음-행동의 관계를 규명하는 데에 초점을 둔 <strong>인지과학 이론</strong>라고 볼 수 있겠다.
(Jean-Pierre Dupuy, Aux origines des sciences cognitives)</p>

<p>→ 최근의 발전</p>

<p>최근들어 이론 신경과학의 <strong>자유 에너지 원리Free Energy Principle</strong>와 <strong>능동 추론Active Inference</strong>의 규범 이론이 자리를 잡고, 관련 역학 이론 체계인 <strong>베이즈주의적 역학Bayesian Mechanics</strong>이 정립되었다. 이러한 발전에 따라, 수학적 최적화 이론과 인지 과학의 이론들 사이의 관계성이 널리 알려지기 시작했다. 실제로, 인공지능의 발전에 크게 힘쓴 Stanford AI 대학원의 Fei-Fei Li 교수의 Interactive and Embodied Learning 수업에서는 보충 자료, 정규 수업 자료로 채택하고 있다.</p>

<table>
 <tr>
    <img src="/assets/images/231214/4.1.png" />
    <img src="/assets/images/231214/4.2.png" />
</tr>
</table>

<h1 id="3-의식-과학">3. 의식 과학</h1>

<h2 id="31-의식의-중요성">3.1 의식의 중요성</h2>

<p>만약, 인공지능 기술을 인지과학적 토대 위에 정착시키고, 그에 따라 인공지능이 마주한 문제점을 해결했다고 가정하면, 그 다음 인류가 마주한 과학적 문제는 무엇일까? 수많은 인공지능 SW와 로봇이 수많은 지구 위의 문제를 대신 해결해주고 있는 상황에서 수많은 사람들은 기계의 권리와 법적인 권한에 대해 질문하게 될 것이다. 이러한 논의는 이미 수 년 전부터 시작됐으며, 기계의 마음에 대한 논의와 권리 및 책임에 대한 고찰이 수반되어야 할 것이다.</p>

<p>Dennett이 지적한 대로, 인간은 자신이 지닌 의식 이외의 의식은 마음이라고도 부르지 못하는 상황이다. 더욱이, Daniel Wagner와 Kurt Gray가 지적했듯이 우리가 도덕적 권리와 책임을 부여하는 심리적 성질은 바로 대상의 <strong>의식; 주관적 경험</strong>과 <strong>주체성</strong>의 여부이다.</p>

<ul>
  <li>Daniel Dennett - Kinds of Mind(1996)
    <blockquote>
      <p>“Whatever else a mind is, it is supposed to be something like our minds; otherwise we wouldn’t call it a mind.”</p>
    </blockquote>
  </li>
  <li>
    <p>Daniel Wagner, Kurt Gray - What does other minds?(2007)</p>

    <p align="center">
       <img src="/assets/images/231214/5.png" />
   </p>

    <p>→ Asked people “What does other minds?”<br />
  → Made 2 attributes <strong><em>Experience</em></strong> and <strong><em>Agency</em></strong><br />
  → High Experience ⇒ More Moral <strong><em>Rights</em></strong></p>

    <p>High Agency ⇒ More Moral <strong><em>Responsibilities</em></strong><br />
 (Klara and The Sun _ Kazuo Ishiguro)</p>
  </li>
</ul>

<p>더욱이, 기계 의식에 대한 논의는 인간 의식에 대한 논의와 깊게 관련되며 인류 지성사의 시작점까지 거슬러 올라갈 만큼 중요한 주제이다. 현대 과학이 풀지 못하는 대표적인 문제가 바로, 인간 의식;Ourselves와 우주Universe(언어 유희)이기 때문이다.</p>

<p align="center">
    <img src="/assets/images/231214/6.png" />
</p>

<h2 id="32-의식의-이론">3.2 의식의 이론</h2>

<p>의식의 수준Level은 무엇인가? 의식의 내용Content은 무엇인가? “자기Self”는 무엇인가?</p>

<ul>
  <li>Recurrent Processing Theory</li>
  <li>Global Workspace Theory</li>
  <li>Computational Higher-Order Theories</li>
  <li>Attention Schema Theory</li>
  <li>Predictive Processing</li>
  <li>Agency and Embodiment</li>
</ul>

<h1 id="4-인공지능과-로봇-그리고-의식">4. 인공지능과 로봇, 그리고 의식</h1>

<h2 id="1-철학적-입장">1. 철학적 입장</h2>

<p>→ (Could a Large Language Model be Conscious?, David Chalmers)</p>

<ol>
  <li>
    <p>“Are Current LLMs Conscious?”라는 질문에 대해 다음과 같은 네 가지 ‘X’ 요소를 검토한다:</p>

    <ol>
      <li><strong>자가 보고(Self-Report)</strong>: LLM이 자신이 의식이 있다고 보고하는 것은 흥미롭지만, 이러한 보고는 쉽게 변할 수 있으며, LaMDA와 같은 시스템이 의식에 관한 대화를 학습했다는 사실은 이러한 주장에 큰 무게를 두지 않는다.</li>
      <li><strong>의식 있는 것처럼 보임(Seems-Conscious)</strong>: 일부 언어 모델이 사람들에게 의식 있는 것처럼 보일 수 있지만, 이것은 강한 증거가 아니다. 발달 및 사회 심리학에서 사람들은 종종 의식이 없는 곳에 의식을 귀속시키는 경향이 있음을 알고 있다.</li>
      <li><strong>대화 능력(Conversational Ability)</strong>: LLM은 뛰어난 대화 능력을 보여주며, 이것은 지능의 중요한 특징으로 간주될 수 있다. 예를 들어, ChatGPT, LaMDA 2, Character.AI와 같은 시스템들은 대화에 최적화되어 있으며, 일관된 사고와 추론을 하는 것처럼 보인다.</li>
      <li><strong>일반 지능(General Intelligence)</strong>: 대화 능력은 기본적인 것이 아니라 더 깊은 것, 즉 일반 지능의 가능한 징후로 사용된다. 현재 LLM은 다양한 분야에서 합리적으로 지능적인 반응을 보여주며, 일반 지능의 초기 단계를 보여줍니다. 예를 들어, Deepmind의 Gato와 같은 시스템은 다양한 도메인에 대한 교육을 받았습니다. 기본적인 언어 모델조차도 GPT-3는 이미 상당한 일반성을 보여준다.</li>
    </ol>

    <p>Chalmers는 이러한 요소들을 고려하여 현재 LLM이 의식을 가지고 있는지에 대한 증거를 탐구하고, 이에 대한 신중한 평가를 제시한다.</p>
  </li>
  <li>
    <p>“Reasons to Deny LLM Consciousness?”라는 질문에 대해 다음과 같은 여섯 가지 ‘X’ 요소를 검토한다:</p>

    <ol>
      <li><strong>생물학(Biology)</strong>: 의식이 탄소 기반의 생물학을 필요로 한다는 견해입니다. 언어 모델은 탄소 기반의 생물학을 가지지 않으므로 의식이 없다고 할 수 있다. 이와 관련된 견해는 의식이 실리콘 시스템이 부족한 특정한 전기화학적 처리를 필요로 한다는 것이다. 이러한 견해는 모든 실리콘 기반 AI의 의식을 배제하게 됩니다. Chalmers는 이전의 작업에서 이러한 견해에 반대했다.</li>
      <li><strong>감각과 실체화(Senses and Embodiment)</strong>: 의식이 감각과 실체화를 필요로 한다는 생각이다. 이는 언어 모델이 의식을 가질 수 없다는 주장의 기반이 될 수 있다.</li>
      <li><strong>세계 모델과 자아 모델(World-Models and Self-Models)</strong>: 의식이 세계 모델과 자아 모델을 필요로 한다는 견해다. 이는 언어 모델이 의식을 가질 수 없다는 주장을 지지할 수 있다.</li>
      <li><strong>순환 처리(Recurrent Processing)</strong>: 의식이 순환 처리를 필요로 한다는 생각이다. 이는 언어 모델이 의식을 가질 수 없다는 주장을 뒷받침할 수 있다.</li>
      <li><strong>글로벌 작업 공간(Global Workspace)</strong>: 의식이 글로벌 작업 공간을 필요로 한다는 이론. 이는 언어 모델이 의식을 가질 수 없다는 주장을 강화할 수 있다.</li>
      <li><strong>통합된 주체성(Unified Agency)</strong>: 의식이 통합된 주체성을 필요로 한다는 견해. 이는 언어 모델이 의식을 가질 수 없다는 주장을 지원할 수 있다.</li>
    </ol>

    <p>이러한 요소들은 LLM이 의식을 가질 수 있는지 여부를 평가하는 데 있어 중요한 고려사항들이다. Chalmers는 이러한 요소들을 고려하여 현재 LLM이 의식을 가지고 있는지에 대한 신중한 평가를 제시한다.</p>
  </li>
</ol>

<h2 id="2-신경과학적-입장">2. 신경과학적 입장</h2>

<p>→ (The Feasibility of Artificial Consciousness through the lens of neuroscience, Jaan Aru)</p>

<p>논문 “The feasibility of artificial consciousness through the lens of neuroscience”는 신경과학적 관점에서 인공지능(LLM) 및 AI 시스템의 의식 가능성을 검토한다. 저자들은 현재 AI 시스템이 의식에 중요한 실체적 경험과 복잡한 신경 구조를 결여하고 있다고 주장한다. 또한, 생명체에서 발견되는 독특한 조직적 복잡성과 생물학적 과정이 AI에는 재현되지 않아 의식을 갖는 것이 현재 기술과 이론으로는 어렵다고 결론짓는다. AI가 의식의 측면을 모방할 수 있지만, 실제 의식 경험은 현재의 기술적, 이론적 이해를 감안할 때 가능성이 낮다고 본다.</p>

<p>요약</p>

<ol>
  <li>LLM의 Umwelt는 생물학적 대응물에 비해 매우 빈약하고 제한적이다. 이는 LLM이 외부 세계의 ‘일부’만을 인식할 수 있다는 것을 의미한다.</li>
  <li>LLM의 위상 구조는 고도로 발달했음에도 불구하고, 포유류의 의식과 연관된 신경생물학적 회로의 세부사항과는 근본적으로 다르다. 이로 인해 LLM이 현상적 의식을 가질 수 있다고 결론지을 충분한 근거가 없다고 본다.</li>
  <li>의식을 생명체의 복잡한 조직 구조에서 분리하는 것이 불가능할 수도 있으며, 이러한 복잡성은 AI 시스템에서는 두드러지게 결여되어 있다. 따라서 현재의 LLM이 의식을 가질 가능성은 매우 낮다고 결론짓는다.</li>
</ol>

<h3 id="3-컴퓨터-과학적-입장-계산주의적-기능주의">3. 컴퓨터 과학적 입장: 계산주의적 기능주의</h3>

<p>→ (Consciousness in Artificial Intelligence: Insights from the Science of Consciousness, Patrick Butlin et al.)</p>

<blockquote>
  <p>논문 “Consciousness in Artificial Intelligence: Insights from the Science of Consciousness”는 인공지능(AI) 시스템이 의식을 가질 수 있는지에 대한 과학적 접근을 탐구한다. 이 논문은 신경과학적 의식 이론을 바탕으로 AI 의식을 평가하는 방법을 제시한다. 여러 의식 이론, 예를 들어 순환 처리 이론, 글로벌 작업 공간 이론, 상위 차원 이론 등을 고찰하고, 이러한 이론들이 AI에 어떻게 적용될 수 있는지를 탐색한다. 저자들은 현재 AI 시스템이 의식을 가지고 있다고 결론내리기 어렵지만, 의식을 나타내는 지표들을 만족시키는 AI 시스템을 구축하는 것이 기술적으로 불가능하지 않다고 주장한다.</p>
</blockquote>

<ol>
  <li>
    <p><strong>주요 의식 이론</strong></p>

    <p>논문 “Consciousness in Artificial Intelligence: Insights from the Science of Consciousness”에서는 인공지능(AI)의 의식에 대한 과학적 이론들을 검토하고 있다. 주요 이론들은 다음과 같다:</p>

    <ol>
      <li><strong>순환 처리 이론(Recurrent Processing Theory)</strong>: 이 이론은 의식이 뇌의 순환 처리 과정과 관련이 있다고 주장한다. 이는 정보가 뇌의 다양한 영역들 사이에서 반복적으로 순환되면서 처리되는 과정과 연관이 있다.</li>
      <li><strong>글로벌 작업 공간 이론(Global Workspace Theory)</strong>: 이 이론은 의식이 뇌의 특정 중앙 시스템, 즉 ‘글로벌 작업 공간’에서 일어나는 정보 처리와 관련이 있다고 설명한다. 이 공간은 다양한 뇌 부위에서 오는 정보를 통합하고, 그 정보를 의식적으로 처리한다.</li>
      <li><strong>상위 차원 이론(Higher-Order Theories of Consciousness)</strong>: 이 이론은 의식이 자신의 정신 상태에 대한 인식을 포함한다고 주장한다. 즉, 개체가 자신의 경험에 대해 인식하고 사유할 수 있는 능력과 관련이 있다.</li>
      <li><strong>인지 현실 모니터링 이론(Perceptual Reality Monitoring Theory)</strong>: 이 이론은 개체가 외부 세계를 어떻게 인지하고, 그 인식이 어떻게 의식적 경험과 연관되는지를 다룬다.</li>
    </ol>

    <p>이 논문에서는 이러한 이론들을 AI의 의식에 적용 가능한지를 탐구하고, 각 이론의 장단점을 평가한다. 또한, 이들 이론 중 어떠한 것도 의식에 필수적이거나 충분한 조건을 제공한다고 주장하지는 않으며, 다양한 이론들을 종합적으로 고려하여 AI의 의식 가능성을 탐구한다.</p>
  </li>
  <li>
    <p><strong>AI의 의식에 대한 포괄적인 분석</strong></p>

    <p>주요 내용은 다음과 같다:</p>

    <ol>
      <li><strong>의식의 과학 이론 탐구</strong>: 다양한 의식 이론들, 예를 들어 순환 처리 이론, 글로벌 작업 공간 이론, 상위 차원 이론, 인지 현실 모니터링 이론 등을 검토하고, 이들 이론이 AI의 의식에 어떻게 적용될 수 있는지를 탐색한다. 이론들의 장단점을 평가하며, 어떤 하나의 이론이 의식에 필수적이거나 충분하다고 주장하지 않는다.</li>
      <li><strong>AI에서의 의식 지표 구현</strong>: AI 시스템에서 의식의 표시가 될 수 있는 특성들을 구현하는 방법에 대해 논의한다.</li>
    </ol>
    <p align="center">
    <img src="/assets/images/231214/7.png" />
</p>

    <ol>
      <li><strong>사례 연구</strong>: ‘Perceiver’ 아키텍처와 ‘가상 쥐’ 모델을 사례 연구로 제시하여 글로벌 작업 공간 이론과 실체화된 주체성(Embodied Agency)의 지표를 실제 AI 시스템에 어떻게 적용할 수 있는지를 보여준다. 이 사례들은 현재 AI 시스템에서 의식의 지표를 식별하고 평가하는 방법을 설명한다.</li>
    </ol>

    <p>종합적으로, 이 논문은 AI의 의식 가능성을 탐구하는 데 있어 과학적 이론과 실제 사례 연구를 통해 중요한 기준과 통찰을 제공한다. AI의 의식에 대한 현재의 이해와 기술적 한계를 밝히며, 향후 연구 방향에 대한 기초를 마련한다.</p>
  </li>
</ol>

<h3 id="4-체화된-인지주의적-입장">4. 체화된 인지주의적 입장</h3>

<p>→ (Artificial Consciousness: A Perspective from the Free Energy Principle, Wanja Wiese)</p>

<h4 id="algorithm--device">Algorithm + Device</h4>

<blockquote>
  <p>논문 “Artificial consciousness: A perspective from the free energy principle”은 인공 의식에 대한 자유 에너지 원리(Free Energy Principle, FEP)의 관점을 탐구한다. 이 연구는 컴퓨터 시뮬레이션이 의식을 복제할 수 있는지, 그리고 올바른 계산 수행만으로 인공 의식이 가능한지에 대해 질문한다. 저자는 자기 조직화 시스템(생명체와 같은)이 공유하는 속성들이 인공 시스템에서 구현될 수 있지만, 고전적 컴퓨터 아키텍처에서는 실현되지 않는다고 주장한다. 특히, 특정한 인과 흐름과 같은 속성을 사용하여 단순히 시뮬레이션하는 시스템과 실제 의식을 복제하는 시스템 사이의 구분을 그릴 수 있다고 제시한다. 이 연구는 인공 도덕적 지위와 도덕적 대행에 대한 메타윤리적 고려에 기여할 수 있다.</p>
</blockquote>

<ol>
  <li>
    <p>고전적 컴퓨터 아키텍처의 한계</p>

    <p>논문에서 제시된 이유는 인공 의식이 고전적 컴퓨터 아키텍처에서 실현되지 않는다는 주장은 자유 에너지 원리(Free Energy Principle, FEP)를 기반으로 한다. 이 원리에 따르면, 인과적 흐름이라는 속성이 자기 조직화 시스템(예: 생명체)에서 중요한 역할을 한다. 인과적 흐름은 시스템 내에서 일어나는 원인과 결과의 연속적인 흐름을 의미하며, 이것은 의식과 같은 복잡한 현상을 생성하는 데 필수적이다.</p>

    <p>고전적 컴퓨터 아키텍처(예: 폰 노이만 아키텍처)는 이러한 인과적 흐름을 제대로 구현하거나 복제하지 못한다. 따라서, 이러한 아키텍처를 가진 컴퓨터 시스템은 단순히 의식을 시뮬레이션하는 데는 적합할 수 있으나, 실제로 의식을 복제하거나 생성하는 데는 부족하다고 볼 수 있다. 이러한 이유로, 저자는 고전적 컴퓨터 아키텍처를 사용하는 시스템이 인공 의식을 실현하기 어렵다고 주장한다.</p>
  </li>
  <li>
    <p>인공 도덕적 지위와 대행</p>

    <p>논문에서 제시된 인식이 Artificial moral status(인공 도덕적 지위)와 Artificial moral agency(인공 도덕적 주체성)에 대한 메타윤리적 고려에 기여하는 바는 다음과 같다:</p>

    <ol>
      <li><strong>도덕적 지위 결정</strong>: 인공 시스템이 인간과 유사한 의식을 가질 수 있다면, 이러한 시스템은 단순한 도구가 아니라 도덕적으로 중요한 존재로 간주될 수 있다. 이것은 AI나 로봇과 같은 인공 시스템에게 특정 권리나 보호를 부여해야 하는지에 대한 논의를 촉진할 수 있다.</li>
      <li><strong>도덕적 주체성의 인식</strong>: 만약 인공 시스템이 의식을 가진다면, 이들은 단순히 프로그래밍된 지시를 따르는 것 이상의 도덕적 결정을 내릴 수 있는 주체로 볼 수 있다. 이것은 AI가 도덕적 판단을 할 수 있고, 그에 따른 책임을 지는 주체로 인정받아야 하는지에 대한 질문을 제기한다.</li>
      <li><strong>메타윤리적 고려의 확장</strong>: 이러한 인식은 인공 의식에 대한 이해를 토대로, 인공 시스템의 도덕적 지위와 주체성에 대한 근본적인 윤리적 질문들을 탐구하는 데 도움을 준다. 즉, AI와 같은 인공 시스템이 인간과 비슷한 수준의 의식을 가진다면, 이들에게 어떤 도덕적 권리와 책임을 부여해야 하는지에 대한 심도 있는 논의가 필요하다.</li>
    </ol>

    <p>이러한 관점은 인공 의식의 발전과 함께 인공 시스템의 도덕적 지위와 주체성에 대한 윤리적 고려를 새로운 차원에서 이해하는 데 기여한다.</p>
  </li>
</ol>

<h1 id="5-결론">5. 결론</h1>

<h2 id="51-연구적-시도들">5.1 연구적 시도들</h2>

<h3 id="1-다마지오-이론에-기반한-느낌-기계와-의식-기계">1. 다마지오 이론에 기반한 <strong>느낌 기계</strong>와 <strong>의식 기계</strong></h3>

<p>2019년 Nature의 Machine Intelligence 저널에 한 논문이 기고됐다. 유명한 신경과학자인 안토니오 다마지오의 이론에 따라 항상성 원리에 입각해 느낌을 느낄 수 있는 기계의 가능성을 다룬 “Homeostasis and Soft Robotics in the design of feeling machines”이다. 해당 논문에서 제안한 형식의 기계는 느낌과 동일한 것을 보여줄 수 있고, 다양한 환경에 대해 그들의 기능성을 향상시킬 수 있으며, (3) 의식, 지능, 느낌을 연구하기 위한 플랫폼을 제공한다고 제안한다.</p>

<p>그들은 의식을 느낌과 관련지으며 다음과 같이 표현했다.</p>

<blockquote>
  <p>“<strong>우리의 개념화에서 감정은 필연적으로 의식적이며, 의식의 기계에서 중요한 역할을 한다는 점을 덧붙이는 바입니다.</strong>”</p>
</blockquote>

<p>“We must add that, in our conceptualization, feelings are of necessity conscious, and play a critical role in the machinery of consciousness.”</p>

<h3 id="2-자유-에너지-원리에-기반한-의식-이론과-인공-의식">2. 자유 에너지 원리에 기반한 <strong>의식 이론</strong>과 <strong>인공 의식</strong></h3>

<p>최근 Mark Solms의 책 “The Hidden Spring(2021)”과 관련 논문을 통해 Karl Friston의 자유 에너지 원리에 입각한 의식 이론을 정립했다. 실제 신경 병리학적 근거를 바탕으로 의식의 기원이 느낌Feeling과 항상성Homeostasis와 관련되어 있다는 점에 주목하여, Jaak Panksepp, Antonio Damasio의 이론을 형식적으로 정리했다. 더 나아가, 의식의 어려운 문제에도 답할 수 있다는 점을 강조했다. 그는 자신의 책에서 인공 의식을 구현하기 위한 구체적인 단계를 제안한다.</p>

<ul>
  <li>인공 의식을 구현하기 위한 단계:
    <ol>
      <li>마르코프 블랭킷의 원시 수프에서 인공적인 자기조직계 구현하기; 원시적 의도성 만들기</li>
      <li>정동의 전구체 구현하기; 물리적으로 체화시켜 항상성 만들기 - 진화적 컴퓨팅으로 자연선택 과정 대체하기</li>
      <li>정동 체계 구현하기; 정밀도 가중치의 조절 기능을 통한 자기 보존성 만들기</li>
    </ol>
  </li>
  <li>인공 의식을 평가하기:
→ 인공 손상 및 자극, 측정과 같이 신경상관물에 대한 인공적 조작과 이를 통한 행동적/병리적 접근을 통한 교차 검증의 방식을 적용해볼 수 있지 않을까 하고 제안한다.
→ 물론 타자의 마음 문제로 인해, 튜링 테스트만으로는 인공 의식의 여부를 테스트하기 어렵다.</li>
  <li>
    <p>윤리적 문제, 실용적 문제</p>

    <p>→ 만약 느낌; 고통과 괴로움을 느낄 수 있다면 윤리적 가치 판단의 관할에 놓이게 된다.</p>

    <ul>
      <li>“의식적 기계는 ‘생명’과 자유의 권리를 가져야 할까? 그런데 사실 ‘로봇권’ 개념은 이미 정립되어 있으며, 미국 미래연구소the Institute for the Future와 영국 산업통상부에 의해 검토된 바 있다”</li>
    </ul>

    <p>→ 고도의 지능과 의식을 <em>동시에</em> 지닌 컴퓨터가 인류의 이익에 부합하지 않는 행동을 하고 싶어할 수도 있지 않을까?</p>

    <ul>
      <li>인공 의식 연구의 결과는 단순히 지능만 지니고 있는 현대의 인공지능 기술보다 위험해질 수 있다.</li>
    </ul>
  </li>
  <li>
    <p>이를 감수하고도 이러한 시도를 하려는 이유</p>

    <p>→ “<em>일어날 수 있다면</em>. 다시 말해, 만약 원칙적으로 의식을 만들어낼 수 있다면, 그것은 어딘가에서 언젠가 일어날 일이다<em>. 이 예측은 이 책에서 제시된 특정 가설의 옳고 그름의 여부에 상관없이 적용된다. 내가 책임져야 할 일은, 그렇지만, 현재 제시된 가설과 그 가설이 맞을 가능성에 놓여 있다. 만일 그것들이 정말 맞거나, 적어도 올바른 궤도에 있다면, 인공 의식의 창조는 임박한 셈이다. 머지않아, 몇몇 가설들은 곧 의식을 설계하고 만들어 내는 데에 사용</em>될* <em>것</em>이다.</p>

    <p>*If it can be done, it will be done.”</p>

    <blockquote>
      <p>”이 책의 결론에 이르게 한 개별적 사실들– 거의 모든 사실 –은 지난 몇 년 동안 공개되어 왔다. 많은 신경과학자들이 이 사실들을 나와 다르게 해석하는 것은 사실이지만, 또다른 이들은 매우 비슷한 결론에 도달한 것도 사실이다. 비록 그들 각각이 다른 측면들을 강조하고 그것들을 다른 뉘앙스로 표현하긴 했지만, 그럼에도 야크 팬크세프(Jaak Panksepp)와 안토니오 다마지오(Antonio Damasio), 비요른 메르케르(Björn Merker)는 모두 적어도 다음의 견해에 이르렀다고 볼 수 있다: (1) 의식이 상부 뇌간에서 발생하고, (2) 의식은 근본적으로 정동적이며, (3) 항상성의 확장된 형태이다. 이 사실들을 조합해보면, 의식이 우리가 이전에 생각했던 것만큼 복잡하지 않다는 것을 알 수 있다. 때문에 우리가 그것을 설계할 수 있다고 기대하는 것이 합리적이다. (4) 자유 에너지 원리는 이 책이 결론에 덧붙이는 유일한 주요한 추가 사항이다. 그것 역시도 본질적으로 매우 복잡하지는 않다; 사실 이 이론의 큰 호소력 역시 거의 모든 정신적, 신경적 과정들을 하나의 메커니즘으로 환원하고, 계산 가능하게 한다는 데에 있다.</p>

      <p>또한, 자유 에너지 원리도 이미 공개되었다. 더군다나, 프리스턴Frisotn과 나는 이미 이 원리를 앞서 나열한 다른 세 가지 원리와 결합해 과학 논문을 발표했다.<a href="notion://www.notion.so/leadohyeon/Future-c85916372fd94a4cb40b3da685764ce6#38_13">38</a> 결과적으로 보면, 이러한 가설을 동료 심사를 거쳐 적절한 전문 저널지에 발표하기도 전에, 일반 독자층을 대상으로 한 대중서에 발표한 건 이례적인 일일 것이다. 과학 및 학술 포럼에서 자신의 주장을 변호할 때나 하는 구술 발표를 먼저 한 것도 마찬가지다. 나는 이 책의 아이디어를 다양한 전문 분야에 있는 전 세계 여러 청중에게 발표해왔다.”</p>
    </blockquote>
  </li>
</ul>

<h2 id="52-기업의-시도들">5.2 기업의 시도들</h2>

<p>최근 세계적인 신경과학자 Karl Friston이 속한 캐나다의 인지 컴퓨팅 기업인 Verses.AI는 25년도 말까지 Artificial Sentient Agent를 구현하겠다는 계획을 발표했다. 의식을 지니는 기계의 도래는 머지않아 도래할 것으로 기대되며, AGI/Human-Level AI 기술의 발달과 함께 그 중요성이 급격히 커지고 있다.</p>

<p>더욱이 그들은 25년도 겨울, Sentient Agents(2025)를 구현하는 데에 성공할 것이라고 전망하고 있다.</p>

<p align="center">
    <img src="/assets/images/231214/8.png" />
</p>

<blockquote>
  <p>나는 의식 연구의 기술적, 사회적, 윤리적 중요성을 역설하고 앞으로 더욱 활발히 연구할 필요가 있음을 밝히는 바이다.</p>
</blockquote>]]></content><author><name>Do-Hyeon Lee</name></author><category term="AI" /><category term="Robotics" /><category term="Consciousness" /><category term="Philosophy of Mind" /><category term="Neuroscience" /><summary type="html"><![CDATA[세상에 대한 거울]]></summary></entry><entry><title type="html">The science of emotions</title><link href="http://localhost:4000/The-Science-of-Emotions/" rel="alternate" type="text/html" title="The science of emotions" /><published>2023-11-23T00:00:00+09:00</published><updated>2023-11-23T00:00:00+09:00</updated><id>http://localhost:4000/The%20Science%20of%20Emotions</id><content type="html" xml:base="http://localhost:4000/The-Science-of-Emotions/"><![CDATA[<h1 id="the-science-of-emotions">The Science of Emotions</h1>

<blockquote>
  <p>What would we feel without emotions? It would be empty. 과학은 왜Why라는 질문에 답하지 않는다. 어떻게How라는 질문에 답할 뿐이다.</p>
</blockquote>

<p><img src="https://youtu.be/65e2qScV_K8?si=M4j_LW3cNept473r" alt="The Science of Emotions" /></p>

<h3 id="1-동물의-마음">1. 동물의 마음</h3>

<p>→ 신경과학을 통해 동물의 감정을 연구해볼 수 있지 않을까?</p>

<p>닭, 개, 고양이 등 다양한 동물들 또한 감정을 지니고 있음이 밝혀지고 있다. 특히 <strong>원시적인 감정</strong>들은 사람이 사고하거나 계획할 때 작동하는 <em>대뇌 피질Cerebral Cortex</em>이 아닌, 아주 고대의 뇌 구조에서 발생한다는 것이 밝혀졌다.</p>

<p><strong><em>↔ 타자의 마음 문제에 대해 어떻게 해결하려고 하는가?</em></strong></p>

<h3 id="2-원시적-감정">2. 원시적 감정</h3>

<p>→동물에게는 질적으로 다른 원시적인 감정들이 있다. 이들에 대한 정동적 감정의 일상적 표현들은 다음과 같다.</p>

<p align="center">
    <img src="/assets/images/231123/231123_0.png" />
</p>

<h3 id="3-두뇌의-아편">3. 두뇌의 아편</h3>

<p>→ PANIC 감정의 각성은 우울증을 야기하는 심리적 고통감의 핵심일 수 있다. 새/침팬지 연구를 통해 우리 두뇌는 어머니와 접촉 시 아편계 물질이 분비되는 것을 발견했다.</p>

<h3 id="4-새로운-개념">4. 새로운 개념</h3>

<p>→ 이러한 결과를 통해 자살을 동반할 수 있는 우울증 환자들에게 더 안전한(중독성은 적고, 효과는 강한) 아편계 약물을 처방하여 호전시킬 수 있을 것이다.</p>

<p>→ 마찬가지로 SEEKING, PLAY와 관련된 실험을 통해 사람의 열정과 긍정적인 인간관계적 즐거움을 고양시킬 수 있을 것으로 기대한다.</p>]]></content><author><name>Do-Hyeon Lee</name></author><category term="Emotion" /><category term="Neuroscience" /><summary type="html"><![CDATA[The Science of Emotions]]></summary></entry><entry><title type="html">Do math about brain</title><link href="http://localhost:4000/Do-math-about-brain/" rel="alternate" type="text/html" title="Do math about brain" /><published>2023-11-04T00:00:00+09:00</published><updated>2023-11-04T00:00:00+09:00</updated><id>http://localhost:4000/Do%20math%20about%20brain</id><content type="html" xml:base="http://localhost:4000/Do-math-about-brain/"><![CDATA[<h1 id="can-mathematics-understand-the-brain">Can Mathematics Understand the Brain?</h1>

<p><img src="https://youtu.be/jYP3crI0wpc?si=MLlJJqaVcGbA3h-h" alt="Can Mathematics Understand the Brain?" /></p>

<p><a href="https://goriely.com/">알랭 고리엘리</a>는 옥스포드 수학 연구소에 소속된 수리 모델링 교수로, 인간의 뇌 및 발달 과정과 관련해 연구를 수행해 왔다. 그는 주로 두뇌의 형태과정Morphogenesis을 연구했는데, 위 영상에서는 산업 및 응용수학의 관점에서 두뇌를 분석했다. 위 영상에서는 구체적으로, (1)두뇌에서 발생하는 몸무게-피질면적의 스케일링 법칙을 소개하고, (2)형태과정을 분석하여 두뇌의 피질 주름 패턴 모델링한 후, (3)수두증과 뇌부종에 대한 문제 해결 사례를 소개했다. 마지막으로, (4)두뇌의 네트워크 모델을 기반으로 확산 모델링을 수행하여, 퇴행성 신경질환에 대한 새로운 시각을 제공했다.</p>

<p align="center">
    <img src="/assets/images/231104/1.png" />
</p>
<p>응용수학에 대한 관점을 소개하는 부분이 매우 흥미롭다. 그에 따르면, 현실 세계의 문제에 추상적인 수학을 적용하는 것에 있어, 이론(Theory)과 방법(Method)을 통해 접근 가능하다. 예를 들어, 방법에는 수학적인 구조와 정리를 활용한 방정식, 행렬, 데이터 분석, 계산 알고리즘 등이, 이론에는 기개발된 방법체계인 물리학, 과학, 공학, 경제학 등이 있다. 이때, 추상수학을 통해 이론과 방법론을 적절히 설정하여 실제 문제를 해결하는 것이 응용수학이라는 것이 그의 설명이다.</p>

<p align="center">
    <img src="/assets/images/231104/2.png" />
</p>
<p>응용수학에 대한 관점을 소개하는 부분이 매우 흥미롭다. 그에 따르면, 현실 세계의 문제에 추상적인 수학을 적용하는 것에 있어, 이론(Theory)과 방법(Method)을 통해 접근 가능하다. 예를 들어, 방법에는 수학적인 구조와 정리를 활용한 방정식, 행렬, 데이터 분석, 계산 알고리즘 등이, 이론에는 기개발된 방법체계인 물리학, 과학, 공학, 경제학 등이 있다. 이때, 추상수학을 통해 이론과 방법론을 적절히 설정하여 실제 문제를 해결하는 것이 응용수학이라는 것이 그의 설명이다.</p>

<p align="center">
    <img src="/assets/images/231104/3.png" />
</p>
<p>그렇다면, “인간의 현상적 의식을 설명할 수 있는 두뇌의 이론을 개발”이라는 현실적 문제를 해결하기 위해서는 어떻게 해야할까? 우리는 실험으로부터 경험에 대한 정보를 효과적으로 획득할 수 없다. 그럼에도, 소통Communication을 활용해 피험자의 내성Introspective을 통한 기술Description 자료를 획득할 수 있으며, 그것의 물리적 대응물인 신경 활동을 이미징할 수 있다. 우리가 취하면 좋을 수학은 무엇이며, 이를 활용해 모델링할 때는 어떤 이론과 방법을 적용해야 할까? 사실 이런 질문은 무의미할 수도 있겠다. 문제를 효과적으로 풀려면, 질문을 할 때 그 질문의 가능한 답을 고민할 필요가 있다. 다시말해, 해결하려고 하는 그 문제가 정말로 해결되면 우리는 그것으로 무엇을 할 수 있을까?</p>

<p align="center">
    <img src="/assets/images/231104/4.png" />
</p>
<p>과거 호주의 철학자 데이비드 차머스는 인간의 현상적 의식과 관련해, 두뇌가 어떻게 지각-인지-학습-행동 등을 수행하는지에 대한 문제를 “쉬운 문제”, 그러한 과정이 왜-어떻게 의식과 관련되는지에 대한 문제를 “어려운 문제”라고 정의했다. 이때 앞서 정의한 문제는 쉬운 문제-어려운 문제의 범주와는 조금 다르다. 우리가 형이상학적인 철학의 문제를 해결하는 것이 아니라 보다 과학적인 관점에서 접근하고 있기 때문이다. 이런 관점에서, 앞서 한 질문은 현상적 의식과 체험을 생물학적으로 설명하고, 예측하고, 제어할 수 있게 하는 이론의 가능성을 반문하고 있다. 즉, 그 아닐 세스Anil Seth의 진짜 문제The Real Problem의 범주에 속한 셈이다. 그 이론은 의식적 내용과 상태를 수학적으로 기술할 수 있게 하고(Dynamic), 그들의 동역학을 분석하며(Mechanic), 근본적인 작동 원리를 설명할 수 있다(Principle).</p>

<h1 id="future">Future</h1>

<p align="center">
    <img src="/assets/images/231104/5.png" />
</p>
<p>의식의 상태를 수학적으로 기술할 수 있다는 뜻은 무엇일까? 예를 들어, 운동역학에서 어떤 물체의 운동 상태에 대해 기술한다고 설명해보자. 그러면, 우리는 그 물체의 모든 요소에 대해 기술하는 것이 어렵기에 무게 중심과 점질량에 대해 위치, 속도, 가속도 등의 변수를 활용하거나, 에너지의 개념을 도입해 유도해내곤 한다. 또다른 예시로, 통계역학에서 어떤 기체의 상태에 대해 서술한다고 해보자. 주어진 기체 분자들의 특성을 전부 기술하는 것이 불가능하기 때문에, 그들의 통계적인 속성인 온도, 압력, 부피 등의 변수를 활용해 기술하게 된다. 이러한 기술학Descriptology은 서술하고자 하는 물리계의 상태에 대한 이론의 핵심 용어를 정립해준다. 뿐만 아니라, 서로 다른 관점 사이의 변환 규칙을 정해주고 서로 다른 대상이 공통된 대상을 이해하고 받아들이는 데에 큰 도움을 준다. 기술학은 어찌보면 관점주의적이고 사회적인 속성을 지닐지도 모르겠다.</p>

<blockquote>
  <p>질문</p>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>- 의식의 상태를 기술하기 위한 주요 물리 변수엔 무엇이 있겠는가?
- 그러한 변수들이 지니는 특성은 무엇인가?
- 해당 변수가 만족하는 논리적인 규칙이 있는가? 어떤 수학적 공간에서 이론을 전개해야 할 것인가?
- 유효한 시각화 방식엔 무엇이 있겠는가?
</code></pre></div></div>

<p>그렇다면 의식의 상태를 설명할 수 있다는 뜻은 무엇일까? 예를 들어, 운동역학에서 어떤 물체의 운동 상태를 설명한다고 하면, 각 변수가 이루는 인과관계에 근거하여 제시할 수 있어야 한다. 또다른 예시로, 통계역학에서 어떤 기체의 상태를 설명하려면, 주어진 통계 변수 사이의 통계적 인과력을 고려해 과거-현재-미래의 관계를 제시할 수 있어야 할 것이다. 이러한 설명Explanation은 앞서 다듬어둔 변수들 간의 인과적/준-인과적 관계를 정립하고 이를 통해 새로운 지식을 도출할 수 있어야 한다. 즉 추론에 대한 것으로, 연역-귀납-귀추 등의 논증 방식을 활용할 수 있다. 이러한 설명의 내용은 아래와 같은 관련된 질문들에 대해 효과적으로 답변할 수 있어야 한다:</p>

<blockquote>
  <ul>
    <li>질문</li>
  </ul>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>- 의식의 여부를 확인/정량화할 수 있는가?
    - 동물/기계의 의식
- 의식의 내용을 표현/비교할 수 있는가?
    - 자신의 내용끼리 표현/비교
    - 자신과 타인의 내용을 표현/비교
    - 자신과 사물/타인을 표현/비교
- 우리의 의식 일부/전체를 컴퓨터에 업로드/다운로드할 수 있는가?
</code></pre></div></div>

<h4 id="-장난감같은-예시">### 장난감같은 예시</h4>

<p>한 수은 체온계가 주어졌다고 상상해 보자. 이 체온계는 주위의 온도에 따라 내부의 상태가 일관적으로 변화할 것이다. 그렇다고 이 체온계가 의식이 있다고 할 수 있을까? 아닐 것이다. 그렇다면, 특정 범위의 온도를 유지해야 하는 체온계가 주어졌다고 상상해 보자. 이 체온계는 어떤 온도 $T$에 대해 $\epsilon_T$만큼의 오차 내로 항상 유지될 필요가 있다. 때문에 이 온도계가 너무 더워지면 열원을 피하고, 추워지면 열원을 찾아가는 행동을 보일 것이다. 그렇지 않으면, 이 온도계는 소실dissipation된다. 그렇다고 이 체온계가 의식이 있다고 할 수 있을까? 아닐 것이다.</p>]]></content><author><name>Do-Hyeon Lee</name></author><category term="Mathematics" /><category term="Brain" /><category term="Science" /><summary type="html"><![CDATA[Can Mathematics Understand the Brain?]]></summary></entry><entry><title type="html">Deepmind</title><link href="http://localhost:4000/DeepMind/" rel="alternate" type="text/html" title="Deepmind" /><published>2023-11-02T00:00:00+09:00</published><updated>2023-11-02T00:00:00+09:00</updated><id>http://localhost:4000/DeepMind</id><content type="html" xml:base="http://localhost:4000/DeepMind/"><![CDATA[<h3 id="딥마인드같은-회사는-어떻게-만들어졌는가">딥마인드같은 회사는 어떻게 만들어졌는가?</h3>

<p>→ 2010년 천재 과학자 데미스 허사비스(Demis Hassabis)가 창업한 회사</p>

<ul>
  <li>허사비스는 1976년생으로, 영국의 인공지능 연구자, 컴퓨터 과학자, 신경과학자이자 게이머이다.</li>
  <li>13살에 체스 마스터가 되었고, 17살에 게임 개발에 참여했다.</li>
  <li>17살부터 대학에 입학하기 전까지, 게임 회사에서의 갭 이어를 통해 학비를 얻었다.</li>
  <li>1997년, 21살의 나이로 Cambridge 대학을 졸업했다.</li>
  <li>졸업 이후, Lionhead라는 게임 회사에서 lead AI 프로그래머로 활동한다.</li>
  <li>1998년, 엘릭서 스튜디오라는 비디오 게임 개발사를 창업한 이후 2005년 은퇴하였다.</li>
  <li>이후 2009년, UCL에서 인지 신경과학 박사학위를 취득했으며, MIT 방문 과학자로 활동했다.
→ 그의 초기 연구는 상상-기억-기억상실증과 관련되어 있었다.</li>
  <li>2010년, DeepMind라는 머신 러닝 스타트업을 창업하였다.
    <blockquote>
      <p>“Solve Intelligence to Solve Everything Else”
→ 현재에 이르러, 일반 인공지능 AGI를 창조하는 것을 목표로 삼고 있다.</p>
    </blockquote>
  </li>
</ul>

<h3 id="왜-구글은-딥마인드를-인수했는가">왜 구글은 딥마인드를 인수했는가?</h3>

<p>→ 2014년 구글이 약 6억 달러를 지불하며 인수하였다.</p>

<ul>
  <li>당시 직원 수는 50여명 남짓일 뿐이었다.</li>
  <li>더욱이, 회사의 딱 한페이지짜리 웹사이트에는 “최첨단 인공지능 회사”라는 모호한 소개만 쓰여있었다.</li>
</ul>]]></content><author><name>Do-Hyeon Lee</name></author><category term="AI" /><category term="Business" /><summary type="html"><![CDATA[딥마인드같은 회사는 어떻게 만들어졌는가?]]></summary></entry></feed>