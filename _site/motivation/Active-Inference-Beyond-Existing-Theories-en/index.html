<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="us" class="no-js">
  <head>
    <meta charset="utf-8" />

<!-- begin _includes/seo.html --><title>Active Inference vs Existing Theories  |  Do-Hyeon Lee</title>
<meta name="description" content="">


  <meta name="author" content="Do-Hyeon Lee">
  
  <meta property="article:author" content="Do-Hyeon Lee">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="us_EN">
<meta property="og:site_name" content="Do-Hyeon Lee">
<meta property="og:title" content="Active Inference vs Existing Theories">
<meta property="og:url" content="http://localhost:4000/motivation/Active-Inference-Beyond-Existing-Theories-en/">


  <meta property="og:description" content="">



  <meta property="og:image" content="http://localhost:4000/assets/images/posts/2024/Q3/2024-08-03-Active%20Inference%20Beyond%20Existing%20Theories/0.webp">





  <meta property="article:published_time" content="2024-08-03T00:00:00+09:00">





  

  


<link rel="canonical" href="http://localhost:4000/motivation/Active-Inference-Beyond-Existing-Theories-en/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "Do-Hyeon Lee",
      "url": "http://localhost:4000/"
    
  }
</script>







<!-- end _includes/seo.html -->
 
<link
  href="/feed.xml"
  type="application/atom+xml"
  rel="alternate"
  title="Do-Hyeon Lee Feed"
/>


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0" />

<script>
  document.documentElement.className =
    document.documentElement.className.replace(/\bno-js\b/g, "") + " js ";
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css" />
<link
  rel="preload"
  href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"
  as="style"
  onload="this.onload=null;this.rel='stylesheet'"
/>
<noscript
  ><link
    rel="stylesheet"
    href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"
/></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->
<link
  rel="apple-touch-icon"
  sizes="152x152"
  href="/favicon.io/apple-touch-icon.png"
/>
<link
  rel="icon"
  type="image/png"
  sizes="32x32"
  href="/favicon.io/favicon-32x32.png"
/>
<link
  rel="icon"
  type="image/png"
  sizes="16x16"
  href="/favicon.io/favicon-16x16.png"
/>
<link rel="manifest" href="/favicon.io/site.webmanifest" />
<meta name="msapplication-TileColor" content="#da532c" />
<meta name="theme-color" content="#ffffff" />
<!-- end custom head snippets -->

  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          Do-Hyeon Lee
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/research/">Research</a>
            </li><li class="masthead__menu-item">
              <a href="/watch/">Watch</a>
            </li><li class="masthead__menu-item">
              <a href="/read/">Read</a>
            </li><li class="masthead__menu-item">
              <a href="/outreach/">Outreach</a>
            </li><li class="masthead__menu-item">
              <a href="/cv/">CV</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person" class="h-card">

  
    <div class="author__avatar">
      <a href="http://localhost:4000/">
        <img src="/assets/images/avatar.jpg" alt="Do-Hyeon Lee" itemprop="image" class="u-photo">
      </a>
    </div>
  

  <div class="author__content">
    <h3 class="author__name p-name" itemprop="name">
      <a class="u-url" rel="me" href="http://localhost:4000/" itemprop="url">Do-Hyeon Lee</a>
    </h3>
    
      <div class="author__bio p-note" itemprop="description">
        <p>Human and Machine Mind-Behavior-Brain Researcher</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      

      
        
          
            <li><a href="https://maps.app.goo.gl/fDF8TMFHnu1fHCBd9" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i><span class="label">Location</span></a></li>
          
        
          
            <li><a href="mailto:lead.o.hyeon@gmail.com" rel="nofollow noopener noreferrer me"><i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i><span class="label">Email</span></a></li>
          
        
          
            <li><a href="https://x.com/HumMachCoevol" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i><span class="label">Twitter</span></a></li>
          
        
          
            <li><a href="https://www.linkedin.com/in/dohyeon-lee-4793a6244" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span class="label">Linkedin</span></a></li>
          
        
          
            <li><a href="https://www.youtube.com/@leadh99" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fab fa-fw fa-youtube" aria-hidden="true"></i><span class="label">YouTube</span></a></li>
          
        
          
            <li><a href="https://github.com/Lee-DoHyeon" rel="nofollow noopener noreferrer me" itemprop="sameAs"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span></a></li>
          
        
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer me">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>



  <article class="page h-entry" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Active Inference vs Existing Theories">
    <meta itemprop="description" content="">
    <meta itemprop="datePublished" content="2024-08-03T00:00:00+09:00">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title p-name" itemprop="headline">
            <a href="http://localhost:4000/motivation/Active-Inference-Beyond-Existing-Theories-en/" class="u-url" itemprop="url">Active Inference vs Existing Theories
</a>
          </h1>
          

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          13 minute read
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content e-content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> Active Inference vs Existing Theories</h4></header>
              <ul class="toc__menu"><li><a href="#active-inference-vs-existing-theories">Active Inference vs. Existing Theories</a><ul><li><a href="#1-philosophy-predictive-theories">(1) Philosophy; Predictive Theories</a></li><li><a href="#2-perception">(2) Perception</a></li><li><a href="#3-action-control">(3) Action Control</a></li><li><a href="#4-utility-and-decision-making">(4) Utility and Decision-Making</a></li><li><a href="#5-behavior-and-bounded-rationality">(5) Behavior and Bounded Rationality</a></li><li><a href="#6-valence-emotion-and-motivation">(6) Valence, Emotion, and Motivation</a></li><li><a href="#7-homeostasis-allostasis-and-interoception">(7) Homeostasis, Allostasis, and Interoception</a></li><li><a href="#8-attention-salience-and-epistemic-dynamics">(8) Attention, Salience, and Epistemic Dynamics</a></li><li><a href="#9-rule-learning-causal-inference-rapid-generalization">(9) Rule Learning, Causal Inference, Rapid Generalization</a></li><li><a href="#10-other-applications">(10) Other Applications</a></li></ul></li><li><a href="#summary">Summary</a></li></ul></li></ul>

            </nav>
          </aside>
        
        <style>
  .centered-container {
      text-align: center;
  }
  figure {
      display: inline-block;
      margin: auto;
      padding: 10px;
      text-align: center;
      background-color: #fff;
  }
  figcaption {
      font-family: "Wanted Sans Variable", "Wanted Sans";
      font-size: 12px;
      color: #555;
      margin-top: 5px;
  }
</style>

<table>
  <tbody>
    <tr>
      <td>This post is a summary of the final chapter of the textbook “<a href="https://direct.mit.edu/books/oa-monograph/5299/Active-InferenceThe-Free-Energy-Principle-in-Mind">Active Inference</a>” by Thomas Parr and Giovanni Pezzulo.</td>
    </tr>
  </tbody>
</table>

<p><br /></p>

<div class="centered-container">
  <figure>
    <img src="/assets/images/posts/2024/Q3/2024-08-03-Active Inference Beyond Existing Theories/0.webp" style="width: 50%; height: auto;" />
    <figcaption>
      A futuristic robot autonomously exploring its environment, learning, and adjusting its behavior.
    </figcaption>
  </figure>
</div>

<h1 id="active-inference-vs-existing-theories">Active Inference vs. Existing Theories</h1>

<hr />

<h3 id="1-philosophy-predictive-theories">(1) Philosophy; Predictive Theories</h3>

<p>Traditional brain and cognitive theories have emphasized feedforward models where stimuli are transformed into responses (with everything in between labeled “cognitive”). However, Active Inference emphasizes prediction and goal-directed aspects. An active inference agent generates predictions based on a generative model, tests hypotheses, updates the model, and actively collects data. This process satisfies both epistemic (information-seeking) and pragmatic (reward-seeking) demands.</p>

<div class="centered-container">
  <figure>
    <img src="/assets/images/posts/2024/Q3/2024-08-03-Active Inference Beyond Existing Theories/1.gif" style="width: 80%; height: auto;" />
    <figcaption>
      A scene from the movie "Dune" where the Kwisatz Haderach foresees the future.
    </figcaption>
  </figure>
</div>

<p><strong>Predictive Processing</strong> Predictive Processing (PP) is a philosophical framework that views the brain and cognition as prediction-centric, using the concepts of “predictive brain” or “predictive mind.” While closely related to Active Inference, PP uses broader concepts such as generative models, predictive coding, free energy, precision modulation, and the Markov blanket. PP has potential applications across various cognitive domains, from perception and behavior to learning and psychopathology, and can integrate simple biological organisms with complex social and cultural structures. Although PP uses familiar concepts like belief and surprise, these terms can have technical meanings. The growing interest in PP has led to diverse theoretical and epistemological interpretations among philosophers, including enactivism, embodied cognition, and non-representational approaches.</p>

<h3 id="2-perception">(2) Perception</h3>

<p>Active Inference views perception as a process of inference based on a generative model. Bayes’ Rule calculates beliefs about hidden states of the environment based on observed data—a concept dating back to Helmholtz (1866) and reinterpreted across psychology, computational neuroscience, and machine learning.</p>

<div class="centered-container">
  <figure>
    <img src="/assets/images/posts/2024/Q3/2024-08-03-Active Inference Beyond Existing Theories/2.png" style="width: 50%; height: auto;" />
    <figcaption>
      The Bayesian Brain Hypothesis: perceiving the world through Bayes' Rule. Source: <a href="">Entropy, Free Energy, Symmetry and Dynamics in the Brain, Viktor Jirsa et al.</a>
    </figcaption>
  </figure>
</div>

<p><strong>Bayesian Brain Hypothesis</strong> The Bayesian Brain Hypothesis modernizes this idea, applying it to decision-making, sensory processing, learning, and more. Active Inference provides a normative basis for these inference ideas, grounded in the principle of minimizing variational free energy. In contrast, the Bayesian Brain Hypothesis models perception and action differently. Active Inference extends the typical process model of predictive coding in perception to the domain of action, explaining action dynamics through generative model principles. The Bayesian Brain Hypothesis includes various theories across computational, algorithmic, and neuronal levels, each with competing theories and multiple ways of implementing Bayesian computation. Active Inference, on the other hand, offers a more integrated perspective by connecting normative principles with process theories. All processes are assumed to minimize free energy, and process theories use gradient descent on free energy, with clear neurophysiological implications. Predictive coding can be derived from the free energy minimization principle and extended to the action domain by adding motor reflexes to the predictive coding agent in continuous time.</p>

<h3 id="3-action-control">(3) Action Control</h3>

<p>In Active Inference, action control is driven by forward prediction, similar to perceptual processing. For instance, the proprioceptive prediction “My hand will grasp the cup” triggers the grasping movement. Action control, unlike perception, relies less on sensory input and is more connected to motor reflexes in the brainstem and spinal cord, receiving relatively less bottom-up input. This is related to the equilibrium point hypothesis, where action sets and maintains a target equilibrium point. To initiate action, prior beliefs and sensory precision must be appropriately modulated; when the prior is more precise, the grasping action occurs. This is achieved through transient sensory attenuation, and failure in sensory attenuation can lead to failure in action control.</p>

<div class="centered-container">
  <figure>
    <img src="/assets/images/posts/2024/Q3/2024-08-03-Active Inference Beyond Existing Theories/3.jpg" style="width: 60%; height: auto;" />
    <figcaption>
      The ideomotor effect: an example of how prior beliefs alone can influence behavior, as seen with the Ouija board.
    </figcaption>
  </figure>
</div>

<p><strong>Ideomotor Theory</strong> In Active Inference, actions are driven by proprioceptive predictions rather than motor commands. This concept is related to William James’ Ideomotor Theory, which suggests that the bidirectional linkage between actions and effects is central to cognitive architecture. In other words, actions generate sensory predictions when moving from action to effect, and actions can be selected based on the expected effect when moving from effect to action. Active Inference extends these ideas by adding concepts such as precision control and sensory attenuation.</p>

<div class="centered-container">
  <figure>
    <img src="/assets/images/posts/2024/Q3/2024-08-03-Active Inference Beyond Existing Theories/4.webp" style="width: 60%; height: auto;" />
    <figcaption>
      Diagram illustrating the history of cybernetics and related fields. Source: <a href="https://www.researchgate.net/profile/Dmitry-Novikov-4v">Dmitry A. Novikov.</a>
    </figcaption>
  </figure>
</div>

<p><strong>Cybernetics</strong> Active Inference emphasizes goal-directed behavior and feedback-based agent-environment interaction, similar to the TOTE model (Test-Operate-Test-Exit), selecting actions based on the difference between a preferred state and the current state. This distinguishes it from behaviorist theories or reinforcement learning, which assume a simple stimulus-response relationship. Instead, Active Inference aligns more closely with Perceptual Control Theory, which also emphasizes controlling perceptual states rather than actions. For example, while driving, we control the desired speed but may choose to accelerate or decelerate based on circumstances. This reflects William James’ insight that “humans achieve stable goals in a flexible manner.” However, while Active Inference includes predictive (feedforward) control through generative models, Perceptual Control Theory assumes that feedback mechanisms alone are sufficient. Both theories describe control through a hierarchical cascade of higher and lower goals, but Active Inference includes a function that prioritizes more salient or urgent goals based on precision-weight modulation by motivational processes.</p>

<div class="centered-container">
  <figure>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/1AR2-OHCxsQ?si=rJ886vqqvCW80lss" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
    <figcaption>
      The famous Model Predictive Path Integral; Information-Theoretic Model Predictive Control algorithm used to power a rally car. Source: Georgia Tech.
    </figcaption>
  </figure>
</div>

<p><strong>Optimal Control Theory</strong> Optimal Control Theory selects motor commands through control policies and cost functions based on stimulus-driven responses. In contrast, Active Inference uses predictive control, where motor commands are considered predictions, with the generative model playing a central role in action control. While Optimal Control requires both a forward model to predict the outcomes of actions and an inverse model to optimize motor commands based on those predictions, Active Inference relies solely on a simple forward model based on reflexes. When sensory prediction errors arise, Active Inference resolves them through action, using simple motor reflexes rather than complex inverse computations. Additionally, Active Inference replaces the cost/value functions used in Optimal Control Theory with Bayesian concepts such as prior preferences or expected free energy.</p>

<h3 id="4-utility-and-decision-making">(4) Utility and Decision-Making</h3>

<p>Active Inference, Optimal Control Theory, economic theory, and reinforcement learning all utilize costs and rewards in selecting actions, but their approaches differ. Optimal Control Theory and reinforcement learning use cost functions and the Bellman equation to optimize behavior, while economic theory focuses on utility maximization. In contrast, Active Inference aims to minimize expected free energy, naturally resolving the exploration-exploitation dilemma. It absorbs the concept of cost into prior preferences, specifying the goal of control and biasing the generative model, using priors instead of value functions to find the optimal policy. This allows Active Inference to perform actions through predictive control, effectively achieving desired states.</p>

<div class="centered-container">
  <figure>
    <img src="/assets/images/posts/2024/Q3/2024-08-03-Active Inference Beyond Existing Theories/5.png" style="width: 40%; height: auto;" />
    <figcaption>
      Example of Bayesian Decision Theory: Bayesian Search Theory applied to find the wreckage of Flight AF447 using Bayes' Theorem. Source: <a href="https://www.metsci.com/what-we-do/featured-projects/the-search-for-air-france-447/">Metron Inc.</a>
    </figcaption>
  </figure>
</div>

<p><strong>Bayesian Decision Theory</strong> Bayesian Decision Theory selects optimal actions by combining Bayesian calculations predicting future outcomes with utility or cost functions defining preferences for future plans. In contrast, Active Inference posits that priors directly signal what is valuable to an organism, optimizing beliefs by minimizing variational free energy and expected free energy. The Complete Class Theorem states that for any decision and cost function, there must exist a prior supporting a Bayes-optimal decision, meaning that when Bayesian Decision Theory separately handles priors and cost functions, it encounters issues of duality or degeneracy. Active Inference resolves this by integrating preferences directly.</p>

<div class="centered-container">
  <figure>
    <img src="/assets/images/posts/2024/Q3/2024-08-03-Active Inference Beyond Existing Theories/6.gif" style="width: 80%; height: auto;" />
    <figcaption>
      Training process of a reinforcement learning agent using NVIDIA's Isaac Sim simulator. Source: <a href="https://pypi.org/project/rl-games/1.1.1/">RL Games, PYPI.</a>
    </figcaption>
  </figure>
</div>

<p><strong>Reinforcement Learning</strong> Reinforcement learning (RL) involves learning policies through trial-and-error, using rewards and value functions to select optimal actions. RL is divided into model-free methods that learn value functions directly, model-based methods that learn value functions and policies from model-generated data, and policy gradient methods that directly optimize policies without value functions. In contrast, Active Inference optimizes beliefs by minimizing variational and expected free energy instead of using rewards and value functions. RL assumes that actions are mediated through trial-and-error learning and reinforcement, while Active Inference assumes that actions result from inference. Additionally, RL sees goal-directed and habitual behaviors as corresponding to model-based and model-free RL, acquired in parallel and competing, while in Active Inference, habitual behaviors can be acquired by repeatedly pursuing goal-directed policies, allowing for cooperation.</p>

<div class="centered-container">
  <figure>
    <img src="/assets/images/posts/2024/Q3/2024-08-03-Active Inference Beyond Existing Theories/7.png" style="width: 70%; height: auto;" />
    <figcaption>
      Scholars who formalized the control and planning problems as probabilistic inference. Source: Personal presentation materials.
    </figcaption>
  </figure>
</div>

<p><strong>Planning as Inference</strong> Just as perception can be viewed as a problem of inference, so too can control and planning be seen as inference problems. This relates to ideas like Control As Inference by Rawlik and Levine, Planning As Inference by Attias, Botvinick, and Toussaint, and Risk-Sensitive, KL Control by Kappen. Active Inference and other “Planning as Inference” theories use dynamic generative models to encode probabilistic relationships between states and actions, inferring action sequences. However, they differ in three main dimensions: (1) inference method, (2) inference target, and (3) inference goal. Active Inference uses variational inference for scalable and efficient computation, infers posteriors over model-based planning, action sequences, or policies, and aims to minimize expected free energy for broader goals. Other theories use different inference methods like sampling, focus on individual actions or action sequences, and aim to maximize rewards.</p>

<h3 id="5-behavior-and-bounded-rationality">(5) Behavior and Bounded Rationality</h3>

<div class="centered-container">
  <figure>
    <img src="/assets/images/posts/2024/Q3/2024-08-03-Active Inference Beyond Existing Theories/8.jpg" style="width: 40%; height: auto;" />
    <figcaption>
      Daniel Kahneman, Nobel laureate and founder of behavioral economics. Source: <a href="https://www.lowyinstitute.org/the-interpreter/daniel-kahneman-psychologist-who-shaped-economics-world">Lowy Institute</a>.
    </figcaption>
  </figure>
</div>

<p>In Active Inference, deliberative, perseverative, and habitual aspects of behavior are automatically integrated. For example, when a person goes shopping, they create a deliberative plan to minimize expected free energy, maintain current behavior by minimizing variational free energy, and perform habitual actions based on past experiences. Unlike Kahneman’s Dual System Theory, this suggests that deliberative, perseverative, and habitual behaviors coexist and cooperate depending on the situation. Deliberative actions vary with cognitive resources, which can carry complexity costs, and the concept of bounded rationality emphasizes balancing the costs, effort, and timeliness of computation. Active Inference views behavior as a result of inference, guiding optimal actions across diverse situations.</p>

<p><strong>Free Energy Theory and Bounded Rationality</strong> Bounded Rationality is explained in terms of Helmholtz Free Energy Minimization, which relates to the concept of variational free energy used in Active Inference. It explains the trade-offs in action selection through the balance between energy/accuracy and entropy/complexity. In Active Inference, free energy is minimized through the trade-off between the cost of increasing precision and accuracy. The concept of bounded rationality resonates with Active Inference, which uses variational bounds to evaluate evidence. As a result, Active Inference offers a model of (bounded) rationality and optimality that finds the best solutions by balancing accuracy and complexity.</p>

<h3 id="6-valence-emotion-and-motivation">(6) Valence, Emotion, and Motivation</h3>

<div class="centered-container">
  <figure>
    <img src="/assets/images/posts/2024/Q3/2024-08-03-Active Inference Beyond Existing Theories/9.png" style="width: 60%; height: auto;" />
    <figcaption>
      The relationship between neuropsychology, cognitive neuroscience, behavioral neuroscience, and cognitive psychology, as outlined by Jaak Panksepp, founder of affective neuroscience. Source: <a href="https://www.psychologytoday.com/sites/default/files/attachments/109303/jcs-articlefinal.pdf">A Synopsis of Affective Neuroscience — Naturalizing the Mammalian Mind(2012), Jaak Panksepp</a>.
    </figcaption>
  </figure>
</div>

<p>Active Inference uses (negative) free energy as a measure of an organism’s ability to achieve its goals, with organisms adjusting their behavior by following the gradient without needing to know the free energy value itself. Emotional valence is explained as the rate of change in free energy over time, with decreases in free energy interpreted as positive valence and increases as negative valence. Moreover, higher-order derivatives can explain more complex emotional states; relief is described as the transition from high to low valence, while disappointment is the transition from low to high. This is related to precision, as it is the second derivative of free energy. Expectations of increases or decreases in free energy play a crucial role in motivation and action selection. The precision of beliefs about policies is linked to dopamine signals, where dopamine bursts can occur when a reliable policy is found. Understanding the neurophysiological mechanisms that connect expectations of achieving goals or rewards with increases in attention and motivation is anticipated.</p>

<h3 id="7-homeostasis-allostasis-and-interoception">(7) Homeostasis, Allostasis, and Interoception</h3>

<p>Active Inference maintains homeostasis by using generative models that explain and regulate an organism’s internal milieu. It activates autonomic reflexes through interoceptive inference to regulate physiological parameters and uses allostatic strategies to minimize expected free energy, proactively preventing interoceptive prediction errors. Physiological regulation plays a key role in affective and emotional processing, with the flow of interoceptive information during external stimulus perception assigning affective meaning to situations. Emotional inference treats emotions as part of the generative model, updating beliefs and regulating behavior. For instance, anxiety is explained by the Bayesian belief “I am anxious,” which accounts for sensory inputs and interoceptive signals, with such predictions adjusting precision or triggering autonomic responses. Typically, interoceptive and exteroceptive sensory information is integrated, with disease research showing a close relationship between emotion, interoception, and attention.</p>

<h3 id="8-attention-salience-and-epistemic-dynamics">(8) Attention, Salience, and Epistemic Dynamics</h3>

<div class="centered-container">
  <figure>
    <img src="/assets/images/posts/2024/Q3/2024-08-03-Active Inference Beyond Existing Theories/10.jpg" style="width: 60%; height: auto;" />
    <figcaption>
      Attention and saliency maps in visual images highlighting key subjects. Source: <a href="https://www.geeksforgeeks.org/what-is-saliency-map/">GeeksForGeeks</a>.
    </figcaption>
  </figure>
</div>

<p>Attention and salience are crucial concepts in psychology. In Active Inference, attention is defined as the precision of sensory input, and salience is defined as expected information gain or epistemic value. Attention is the selection of sensory data that has a greater influence on belief updating, while salience is the stimulus expected to provide more information; attention is the potential to infer, and salience is the potential to learn. Metaphorically, attention is the process of selecting the highest quality data from already measured data for hypothesis testing, while salience is the process of designing the next experiment to obtain the highest quality data. The formal approach of Active Inference resolves the ambiguity of attention and salience and explains why these two concepts are often confused. Epistemic dynamics describe how these concepts influence information acquisition and action decisions.</p>

<h3 id="9-rule-learning-causal-inference-rapid-generalization">(9) Rule Learning, Causal Inference, Rapid Generalization</h3>

<div class="centered-container">
  <figure>
    <img src="/assets/images/posts/2024/Q3/2024-08-03-Active Inference Beyond Existing Theories/11.jpg" style="width: 80%; height: auto;" />
    <figcaption>
      Neuro-symbolic AI, a recent research program focusing on rule and symbol learning. Source: <a href="https://youtu.be/16X0RB_YrvE?si=4BMivbBypHkrlLhA">Presentation by Prof. Yison Yue at Caltech</a>.
    </figcaption>
  </figure>
</div>

<p>The learning paradigm in Active Inference is based on developing generative models that capture causal relations between actions, events, and observations. Humans learn the latent structure of the environment through complex causal inference and generalization, contrasting with current machine learning approaches based on simple pattern recognition. Learning hidden rules allows for better predictions and generalization with fewer sensory details. This ability enables efficient learning in new situations and the development of a learning-to-learn capability. Active Inference emphasizes balancing accuracy and complexity in models, with model reduction being an effective method not only for preventing the waste of resources but also for learning hidden rules.</p>

<h3 id="10-other-applications">(10) Other Applications</h3>

<p>Beyond survival and adaptation, Active Inference can be applied to various fields, including social and cultural dynamics, machine learning, and robotics. In social and cultural dynamics, it explores the effects of interactions between agents. In machine learning and robotics, it studies learning mechanisms for solving more complex problems in ways compatible with the theory.</p>

<p><strong>Social and Cultural Dynamics</strong> Human cognition is deeply intertwined with social and cultural dynamics rather than isolated individual cognition. Social dynamics, ranging from physical interactions like team sports to abstract interactions like elections, require interaction between multiple Active Inference agents. Simple simulations have already shown interesting emergent phenomena such as self-organization in simple life forms resisting extinction, morphogenetic processes acquiring and restoring body shapes, and mutual coordinated prediction and take-turning. These studies suggest that cognition extends beyond the skull into social niches. Active Inference has the potential to expand from the science of individuals to the science of societies.</p>

<p><strong>Machine Learning and Robotics</strong> In machine learning and robotics, generative modeling and variational inference methods are widely used. Early connectionist generative models like the Helmholtz Machine and Boltzmann Machine provided methods for learning the internal representation of neural networks in an unsupervised manner, closely related to variational approaches. Recent models like Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs) are widely used for recognizing or generating images and videos. VAEs learn accurate descriptions of data while minimizing complexity, and GANs generate high-quality data through competition between generative and discriminative networks. Generative models are also used in high-dimensional movement control in robots, enabling learning through autonomous exploration, demonstration by humans, and interaction with humans. Active Inference provides an effective approach to addressing these challenges and contributes to the development of more advanced robotic technologies.</p>

<h2 id="summary">Summary</h2>

<blockquote>
  <p>Daniel Dennett’s criticism is valid. The traditional engineering problem-solving paradigm has focused on individually implementing sub-systems of cognitive functions, but the results have been far from achieving human-level artificial intelligence. Now, we must develop active inference agents based on a more comprehensive understanding of human and animal cognition. This approach will lead to more complex, energy-efficient, and effective technologies than simple system integration. Applying insights from neurobiology will enable the implementation of more sophisticated AI.</p>
</blockquote>

<blockquote>
  <p>Developing human-level AI requires not only technological innovation but also deep philosophical reflection on how that technology will impact our lives and society. While the Active Inference paradigm is normative and thus not scientifically falsifiable, it will play a crucial role in integrating diverse knowledge and discovering creative solutions.</p>
</blockquote>

        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#behavior" class="page__taxonomy-item p-category" rel="tag">Behavior</a><span class="sep">, </span>
    
      <a href="/tags/#brain" class="page__taxonomy-item p-category" rel="tag">Brain</a><span class="sep">, </span>
    
      <a href="/tags/#engineering" class="page__taxonomy-item p-category" rel="tag">Engineering</a><span class="sep">, </span>
    
      <a href="/tags/#mind" class="page__taxonomy-item p-category" rel="tag">Mind</a><span class="sep">, </span>
    
      <a href="/tags/#neuroscience" class="page__taxonomy-item p-category" rel="tag">Neuroscience</a><span class="sep">, </span>
    
      <a href="/tags/#philosophy" class="page__taxonomy-item p-category" rel="tag">Philosophy</a><span class="sep">, </span>
    
      <a href="/tags/#science" class="page__taxonomy-item p-category" rel="tag">Science</a><span class="sep">, </span>
    
      <a href="/tags/#theory" class="page__taxonomy-item p-category" rel="tag">Theory</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#motivation" class="page__taxonomy-item p-category" rel="tag">Motivation</a>
    
    </span>
  </p>


        

  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time class="dt-published" datetime="2024-08-03T00:00:00+09:00">August 3, 2024</time></p>

      </footer>

      <section class="page__share">
  

  <a href="https://twitter.com/intent/tweet?text=Active+Inference+vs+Existing+Theories%20http%3A%2F%2Flocalhost%3A4000%2Fmotivation%2FActive-Inference-Beyond-Existing-Theories-en%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2Flocalhost%3A4000%2Fmotivation%2FActive-Inference-Beyond-Existing-Theories-en%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=http%3A%2F%2Flocalhost%3A4000%2Fmotivation%2FActive-Inference-Beyond-Existing-Theories-en%2F" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/motivation/Insights-on-Active-Inference-kr/" class="pagination--pager" title="능동추론이 주는 통찰
">Previous</a>
    
    
      <a href="/motivation/Active-Inference-Beyond-Existing-Theories-kr/" class="pagination--pager" title="능동추론 vs 기존 이론들
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      <h2 class="page__related-title">You May Also Enjoy</h2>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/500x300.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/Belief-and-f-kr/" rel="permalink">Belief and f/kr
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          less than 1 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">믿음이란 무엇이고, 어떻게 가능한가?

</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/posts/2024/Q3/2024-07-10-ASSC%20in%20Tokyo/240706/5.jpg" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/meditation/Probability-and-Meaning-kr/" rel="permalink">확률과 정보에 대한 고찰
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          1 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">베이즈 두뇌 가설과 확률적 추론

</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/posts/2024/Q3/2024-09-24-Energy%20Based%20Net%20for%20Top%20Opt/TopOpt%20of%20a%20Compliance%20Prob.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/meditation/Energy-Based-Net-for-Top-Opt-kr/" rel="permalink">에너지 기반 네트워크를 활용한 형상 최적화
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          2 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">

</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <img src="/assets/images/posts/2024/Q3/2024-09-24-Energy%20Based%20Net%20for%20Top%20Opt/TopOpt%20of%20a%20Compliance%20Prob.png" alt="">
      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/meditation/Energy-Based-Net-for-Top-Opt-en/" rel="permalink">Shape Optimization Using Energy-Based Networks
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          3 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">

</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>

    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
          <li><a href="https://x.com/HumMachCoevol" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://www.linkedin.com/in/dohyeon-lee-4793a6244" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> Linkedin</a></li>
        
      
        
          <li><a href="https://www.youtube.com/@leadh99" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-youtube" aria-hidden="true"></i> YouTube</a></li>
        
      
        
          <li><a href="https://github.com/Lee-DoHyeon" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2024 Do-Hyeon Lee. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
<script src="/assets/js/main.min.js"></script>
 

<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>  

    
  <script>
    var disqus_config = function () {
      this.page.url = "http://localhost:4000/motivation/Active-Inference-Beyond-Existing-Theories-en/";  /* Replace PAGE_URL with your page's canonical URL variable */
      this.page.identifier = "/motivation/Active Inference Beyond Existing Theories/en"; /* Replace PAGE_IDENTIFIER with your page's unique identifier variable */
    };
    (function() { /* DON'T EDIT BELOW THIS LINE */
      var d = document, s = d.createElement('script');
      s.src = 'https://lee-dohyeon-github-io.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>


  
 

<script type="text/x-mathjax-config">

  MathJax.Hub.Config({

    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}

  });
</script>

<script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML"
  async
></script>


  </body>
</html>
