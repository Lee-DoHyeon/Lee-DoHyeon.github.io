---
scope:
  type: posts
values:
  layout: single
  author_profile: true
  read_time: true
  comments: true
  share: true
  related: true
---

# Schmidhuber and Conscious Machine

[https://youtu.be/q4fFuZgOZn8?si=7g5nCK04dUgDIVZr](https://youtu.be/q4fFuZgOZn8?si=7g5nCK04dUgDIVZr)

In the 2016 AI Conference held in New York, Jürgen Schmidhuber introduced intriguing concepts such as **Artificial Consciousness**, **World Model**, **Predictive Coding**, and **Data Compression**. He claims that artificial systems possessing consciousness already exist in his lab and that consciousness is a byproduct of data compression occurring during problem-solving processes. Let's explore his main ideas.

### 1. The Foundation of Artificial Consciousness: Data Compression

Schmidhuber explains consciousness as a byproduct of data compression. According to his theory, an artificial system's ability to efficiently compress data during problem-solving forms the basis of consciousness. This is similar to how the human brain processes and stores complex information.

![Untitled](assets/images/240720/Untitled.png)

### 2. General-Purpose Computers and Recurrent Neural Networks

General-purpose computers, especially recurrent neural networks, consist of many nodes connected by short wires to optimize communication costs. These computers gather various information from the world to achieve goals or optimize rewards, with recurrent neural networks playing a crucial role in this process.

### 3. World Models and Predictive Coding

![Untitled](%assets/images/240720/Untitled₩1.png)

Schmidhuber proposes a system that solves reinforcement learning and planning problems based on two recurrent neural networks: a controller and a world model. The controller generates actions, and the world model compresses data through predictions about the world. All physical and scientific laws are compressed into sub-networks of the recurrent network, utilized by the controller.

### 4. Self-Awareness and Artificial Curiosity

![Untitled](assets/images/240720/Untitled₩2.png)

![Untitled](assets/images/240720/Untitled₩3.png)

In the interaction process with the world, artificial systems also compress their own states, forming the basis of self-awareness. Additionally, Schmidhuber introduced artificial curiosity through Generative Adversarial Networks (GANs), presenting agents learning intrinsic motivation via un/self-supervised learning. This is based on a minimax game where a neural network minimizes a cost function maximized by another network.

### 5. Neural Networks as Programs

Schmidhuber argues that the weights of neural networks should be considered as programs. The main goal of deep neural networks is to learn useful internal representations of observed data. The output of neural networks is differentiable with respect to the program, guiding the search for better programs.
![Untitled](assets/images/240720/Untitled₩4.png)

### 6. Predictive World Models and Self-Awareness

![Untitled](assets/images/240720/Untitled₩5.png)

A predictive world model interacting with the world through a controller learns to efficiently encode behaviors and observations via predictive coding during its lifetime. In this process, the world model forms a hierarchy of features, identifying singularities or generating prototype encodings from the given data structure.

### Conclusion

> For 30 years, Jürgen Schmidhuber has been researching machines possessing artificial consciousness and emotions. His work suggests that artificial systems can form self-awareness, interact with the world, and ultimately possess emotions and consciousness through data compression, recurrent neural networks, world models, and predictive coding. This research offers a new perspective on the future of artificial intelligence, contributing to the development of more advanced artificial systems.

### Reflection

Considering the rising importance of predictive coding and un/self-supervised learning in the 2010s, it is remarkable that Schmidhuber recognized their significance and applied these concepts in various cases as early as the early 1990s. Anil Seth's theory in the 2010s posits that predictive coding of interoceptive information forms the basis of consciousness and self-awareness, aligning with Schmidhuber's concept of compressed self-states in world models. Additionally, Schmidhuber's data compression perspective relates to Samuel Gershman's recent principle of approximation in human cognition. While data compression isn't always feasible, Schmidhuber's assertion that hierarchical structures form and compress in recurrent neural networks is deeply relevant.

In his 2003 follow-up research, Schmidhuber introduces a formal definition of consciousness. If consciousness is defined as the ability for unlimited self-examination and self-modification, the Gödel machine provides a technical justification for artificial intelligence consciousness. By enabling limited self-examination and self-modification, these machines offer a framework for a general problem solver capable of autonomously improving and optimizing its behavior. This achieves a form of AI consciousness based on mathematical proofs and formal reasoning.

Schmidhuber's stance on informatics and formal-theoretic approaches is attractive, combining clarity and profound insights. However, considering the evolutionary biological complexity and psychological functionalities, it is crucial to explore the connections with computational neuroscience and philosophy. For instance, explaining how primordial consciousness, as suggested by affective neuroscience, evokes feelings and emotions in agents with world models. Moreover, in-depth research on the relationship between his theory and interoceptive inference, self, attention, consciousness, metacognition, and Gödel machines is necessary.

---

### Summary

> At the 2016 AI Conference, Jürgen Schmidhuber introduced concepts like artificial consciousness, world models, predictive coding, and data compression, explaining consciousness as a byproduct of data compression in problem-solving processes. He proposed a system using general-purpose computers and recurrent neural networks to gather information from the world and achieve goals, employing controller and world model recurrent neural networks for reinforcement learning and planning. These systems efficiently compress data, form self-awareness, and consider neural network weights as programs to find better ones. Notably, Schmidhuber's early recognition and application of the importance of predictive coding and un/self-supervised learning in the early 1990s are impressive. His ideas connect with Anil Seth's theory of predictive coding of interoceptive information and Samuel Gershman's principle of data compression. Through the Gödel machine, which defines consciousness as unlimited self-examination and self-modification, he provides a technical justification for AI consciousness.
>
> While Schmidhuber's research offers clear and profound insights from an informatics and formal-theoretic perspective, exploring its relevance to biological complexity and psychological functions is necessary. This includes explaining how primordial consciousness evokes feelings and emotions in agents with world models, and investigating the relationships between his theory and interoceptive inference, self, attention, consciousness, metacognition, and Gödel machines.

### Reference

**[1] [Jürgen Schmidhuber's Solution to AI Consciousness](https://youtu.be/q4fFuZgOZn8?si=yJkWs44y-QBFlKN2)**

**[2] [1990: Planning & Reinforcement Learning with Recurrent World Models and Artificial Curiosity](https://people.idsia.ch/~juergen/world-models-planning-curiosity-fki-1990.html)**

**[3] [1991: First very deep learning with unsupervised pre-training](https://people.idsia.ch/~juergen/very-deep-learning-1991.html)**

**[4] [Godel Machines: Towards a Technical Justification of Consciousness](https://mediatum.ub.tum.de/doc/1290203/document.pdf)**

**[5] [X](https://x.com/SchmidhuberAI/status/1765769164709371978)**
